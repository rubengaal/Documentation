% !TeX spellcheck = hu_HU
\documentclass[12pt,a4]{article}
\usepackage{xurl}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{lipsum}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[super]{nth}
\usepackage{graphicx}
\usepackage[section]{placeins}
\usepackage{mdframed}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage{indentfirst}
\usepackage{multicol}
\usepackage{mathtools}
\usepackage[figurename=Ábra]{caption}
\hypersetup{
	colorlinks=true,
	linkcolor=black,
	filecolor=magenta,      
	urlcolor=cyan,
	bookmarks=true,
	pdfpagemode=FullScreen,
}
\usepackage{array}
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
\newcolumntype{M}[1]{>{\centering\arraybackslash}m{#1}}

\hyphenation{op-er-and op-er-ands}

\def\magyarOptions{defaults=hu-min}
\PassOptionsToPackage{magyar}{babel}
\usepackage[inputenc=utf8]{uni8}

\begin{document}	
	
	\renewcommand*\contentsname{Tartalomjegyzék}	
	
	\begin{titlepage}
		\begin{figure}
			\centering
			\begin{minipage}{.5\textwidth}
				\centering
				\includegraphics[width=.9\linewidth]{oelogo}
			\end{minipage}%
			\begin{minipage}{.5\textwidth}
				\centering
				\includegraphics[width=.3\linewidth]{oe}
			\end{minipage}
		\end{figure}
		\vspace{0.5cm}			
		\begin{center}			
			\Large
			Óbudai Egyetem\\
			Neumann János Informatikai Kar\\
			
			\vspace*{0.5cm}
			
			\Huge
			\textbf{3D-s arckép rekonstrukciója egy 2D-s képből mesterséges intelligencia segítségével}
			\par\noindent\rule{\textwidth}{0.4pt}
			
			\vspace{0.5cm}
			\normalsize
			Reconstructing 3D face picture from single 2D picture supported by artificial intelligence
			
			\vspace{0.2cm}
			\large
			\today
			
			\vspace{1cm}
			
			Témavezető:\\
			\textbf{Vámossy Zoltán}\\
			Egyetemi docens
			
			\vspace{1cm}
			
			Készítette:\\
			\textbf{Gaál Bernát Ruben - HBGCXK\\
			Hua Nam Anh - DQ4LFK}					
		\end{center}
	\end{titlepage}
	\renewcommand*\contentsname{Tartalomjegyzék}
	\tableofcontents
	\newpage
	\par\noindent\rule{\textwidth}{0.4pt}
	\section*{Absztrakt}
	 \emph{
		A közelmúltban a mélytanuláson alapuló 3D arcrekonstrukciós módszerek
		ígéretes eredményeket mutattak mind minőség, mind hatékonyság tekintetében. A neurális hálózatok tanítása azonban jellemzően nagy mennyiségű
		adatot igényel, ami magával vonza a megfelelő erőforrásokat.
		A felsoroltak hiányában mi az alábbi megoldást javasoljuk. Egy gyengén
		felügyelt tanítású hálózatot amit, lehetséges ”in-the-wild” képekkel betanítani.
		Ennek megvalósításához kettő már kész kutatás anyagát vettük igénybe. Az
		első, \cite{deca}DECA képes kezelni az arc kisebb részleteit, arckifejezéseit. A
		másik, a \cite{focus}FOCUS bemutatott egy korszerű megközelítést az arckép rekonstrukciójára okklúziók mellet, mint például szemüveg,sapka stb. Ezek a kutatások nem csak korszerűek, de a NOW challenge benchmark-ja alapján bizonyitottan jól teljesítenek. Ezeket ötvözve egy robosztus, illetve realisztikus
		arcképek generálására alkalmas módszert mutatunk be ebben a tanulmányban.
		A rekonstrukció mellet implementáltunk egy arckép analízálására alkalmas módszert, amely képes eldönteni az arcképen lévő személy érzelmi
		állapotát és korát. Ezek köré egy felhasználó barát microservice alapú web
		applikációt biztosítunk, melynek szolgáltatásai felhőn üzelmelnek.
		}
	 \par\noindent\rule{\textwidth}{0.4pt}
	 
\section{Bevezetés}
	  
	   Az elmúlt évek során, egyre több figyelmet kaptak a digitális
	 képfeldolgozáson alapuló technológiák az informatikában. Mint ahogy \cite{survey} is megvan említve az arcfelismerő technológiák széles
	 körben elterjedtek napjainkban, beleértve a biztonságot, animációt és egészségügyet. Illetve, ezen szakmai területen mostanság felkapott,
	 hogy 3D-s adatok implementálásával megkerüljék a 2D arckép által megszabott határokat, mivel a 2D-s kép képtelen az emberi arc geometriájának eltárolására.
	 A 3D arcfelismerés sokkal pontosabb adatokat ad vissza, például pózban és megvilágításban, amelyek hátulütői a 2D-nek. Azonban ennek is vannak hátrányai, mint például, hogy sokkal nagyobb komplexitású képfeldolgozást igényel, ezáltal szűkítve a lehetőségeket.
  
Az arcokat többféleképpen is lehet rögzíteni, például Stereo-vision rendszerekkel, amelyek két kamerát használnak. Ezek a kamerák ugyan arról az objektumról készítenek párhuzamosan képeket, majd ezeket összehasonlítva visszaadják a képen lévő egy pontnak a mélységét.  

Egy másik módszer a 3D lézerszkenner (pl. NextEngine, Cyberware), amelyet elsősorban ipari célokra fejlesztettek. Ipari termékek vizsgálatával szemben, az emberi arc feltérképezéséhez több feltételt kell figyelembe venni. Mivel az emberi arc nem lehet teljesen mozdulatlan, fontos, hogy a szkenner által készített felvétel időintervalluma csekély legyen.
Röviden, a lézerszkenner fényhullámokat szór az objektumra, s ezek annak felszínéről visszaverődnek a szenzorra. A szenzor ezután kiszámítja az objektum felszínének távolságát az alapján, hogy mennyi idő alatt tette meg a teljes utat a hullám. Ezt a folyamatot $"Time\enspace of\enspace flight"$-nak szokás nevezni. 
  
	 A következő technológia a 3D-s adatok rögzítésére az RGB-D kamerák (pl. Kinect) használata. Ezek olyan RGB kamerák, amelyek rendelkeznek infravörös szenzorral, mely mélységi adatokat biztosít, ezáltal egy RGB képet ad vissza, amiben minden pixelhez tartozik egy mélységi érték.
  
	 Bár, ezek a módszerek mind megfelelnek 3D-s adatok gyűjtésére, az első két megvalósítás hátránya, hogy előre megszabott feltételeknek megfelelő környezetet és drága felszereléseket igényel egy jó minőségű arc szkenneléshez. Ellenben, az RGB-D kamerák olcsóbbak és könnyebben használhatóak de a minőség korlátozott.
  
	 A fent említett megközelítések általában költséges optimalizálási folyamatot igényelnek a jó minőségű 3D-s arc visszanyerése érdekében. Két évtized telt el Vetter és Blanz úttörő munkája óta \cite{blanzvetter}, amely először mutatta be hogyan lehet egyetlen képből rekonstruálni az arc 3D-s geometriáját. Azóta a 3D arcrekonstrukciós módszerek rohamosan fejlődtek, de a korábbi modellek csak az arc durva alakját tudták rekonstruktuálni és képtelenek voltak kinyerni az arckifejezéstől függő geometriai részleteket, mint például a ráncokat, amik fontosak a realisztikusság szempontjából.
	 
    Később jöttek újabb modellek, melyek képesek voltak kiragadni a fent említett geometriai részleteket, azonban hátrányuk, hogy egy nagy volumenű,
 jó minőségű tanító adathalmazt követelnek. Illetve, egy másik hátrányuk, hogy inkonzisztens módon teljesítettek az okklúziókkal szemben. Az okklúziók mindenütt jelen vannak, és eleve nehezen kezelhetőek az alakjuk, megjelenésük és a pozíciójuk sokfélesége miatt. Ezáltal okozott probléma az, hogy az arcmodell alkalmazkodik az eltakart arcrégióhoz, és ennek eredményeként a rekonstruált arc torz lesz. Ezért fontos nyitott kérdés marad annak eldöntése, hogy mely pixelek illeszkedjenek és melyek ne illeszkedjenek az arcra egy 3D arc rekonstrukciója során okklúziók jelenlétében. A közelmúltban számos olyan módszert javasoltak, amelyek gyengén felügyelt tanítású konvolúciós neurális hálózatokat(CNN) használnak a hatékony, robosztus és a fent említett kihívásokat leküzdő arcrekonstrukció eléréséhez.
	 
    Tehát, a jelenlegi monokuláris 3D arcrekonstrukciós módszerek képesek finom geometriai részleteket visszaadni, azonban számos megkötéssel
küzdenek. Egyes módszerek olyan arcokat generálnak, amelyeket nem lehet valósághűen animálni, mivel nem modellezik, hogy hogyan változnak a ráncok az arckifejezésekkel. Más módszerek kiváló minőségű szkennelt arcokat használnak tanításhoz, és nem jól általánosíthatóak a természetes körülményekben készült képekre. A Yao Feng et. al. által bemutatott DECA model a legelső olyan megközelítés \cite{deca}, amely regresszálja a 3D arcformát és az animálható részleteket, amelyek egy személyre jellemzőek, de az arckifejezéssel változnak, ezáltal képesek az arc valósághű animálására.
	 
Az okklúziókkal szemben a legtöbb megközelítés a 3D arc illesztéséhez inverz renderelést alkalmaz egy adott eltakaró szegmentálásához. Ennek hátránya, hogy egy okklúzió szegmentációs modellhez nagy mennyiségű annotált adatra van szükség. Chunlu Li et. al \cite{focus} ezzel ellentétben egy olyan modellalapú megközelítést mutat be a 3D arc rekonstrukciójához, amely rendkívül robosztus az okklúziókkal szemben, de nem igényel semmilyen okklúziós annotációt a tanításhoz.
	 
Ebben a tanulmányban az a célunk, hogy egy olyan animálható 3D arcrekonstrukciós modellt készítsünk gyengén felügyelt tanulással, amely robosztus az okklúzió ellen, a fent említett DECA és FOCUS modellek segítségével. Ezt kiegészítve, bemutatunk egy arcképet elemző megoldást, mely visszaadja a célszemély érzelmi állapotát, illetve életkorát. Eszrevettük a munkánk elkészítése során, hogy a meglévő megoldásokat nehéz egy átlagos személynek kipróbálnia technikai tudás hiányában, így a fenti két szolgáltatás köré egy webapplikációt készítünk, amit felhőn üzelmeltetünk.\\
	 
Összefoglalva, ez a dokumentum az alábbi öt szempontot fogalmazza meg:
\begin{itemize}
	 \item Bemutatunk egy CNN-alapú, egyetlen képen alapuló arcrekonstrukciós módszert, amely kihasználja a hibrid szintű képinformációt a gyengén felügyelt tanuláshoz.
	 \item Konzisztens műkődést biztosít különböző okklúzók mellet.
	 \item Az arckifejezésektől függő geometria adatok azonosításával egy animálható realisztikus 3D arcrekonstrukciót hozunk létre.
	 \item Arc elemzésére alkalmas megoldás.
	 \item Webapplikáció elkészítése és a szolgáltatások megfelelő mükődése a felhőn
\end{itemize}

 
\section{Kapcsolódó kutatások}
 	
    Ahogy láthatjuk, különböző munkák megkísérelték a fellépő komplex kihívásokat legyőzni, minél kreatívabb megközelítéssekkel. Ezekről tovább Vetter és Blanz \cite{blanzvetter} munkájában és további dokumentumokban lehet olvasni. Ebben a fejezetben megvizsgáljuk a Yao Feng et. al. \cite{deca} valamint Chunlu Li et. al \cite{focus} által bemutatott megközelítéseket és megnézzük, hogy miért is fontosak a mi munkánk szempontjából.
 	
 	\subsection{DECA}
 	
    Yao Feng et. al.\cite{deca} az egyetlen, ”in-the-wild” 2D-s képből rekonstruált animálható 3D arcmodell készítése érdekében fejlesztették ki a DECA (Detailed Expression Capture And Animation) modelljét. Egy ”in-the-wild” képekkel tanított animálható elmozdulási modellt javasolnak, amely a kifejezési paraméterek változtatásával képes hiteles geometria részletek előállítására. Az előbbi cél elérése érdekében egy újszerű részletkonzisztencia költségfüggvényt mutatnak be a statikus és az arckifejezésekre dinamikusan változó geometriai adatok szétválasztására. Ammennyiben a tanítás során két kép érkezik különböző arckifejezésekkel, megfigyelhető, hogy a 3D arcformájuk és a személyspecifikus részleteik megegyeznek. Ezt a megfigyelést használják ki a részletkódok felcserélésével az azonos személyről készült különböző képek között, és kikényszerítik, hogy az újonnan renderelt eredmények úgy nézzenek ki, mint az eredeti, bemenetként átadott képek. A geometria részletek rekonstrukciója robosztus a jellemző okklúziókra, a pózok nagyfokú változására és a megvilágítási variációkra.
 	
 	A továbbiakban megvizsgáljuk a DECA modell működési elvét, architektúráját.
 	
 	\begin{figure}[h]	
 		\centering
 		\includegraphics[width=1\linewidth]{deca}
 		\caption{ DECA tanítás és animáció.
 			Forrás:\cite{deca}}
        \label{fig:deca}
 	\end{figure}
 	
	 \subsubsection{Kódoló}
	 Első lépésként egy durva rekonstrukciót (a FLAME modelltérben \cite{flame}) tanítanak be $analysis$-$by$-$synthesis$ módon: egy bemenetként átadott \textit{I} 2D-s képből látens kódot készítenek, ezt dekódolják annak érdekében, hogy egy $I_{r}$ 2D-s képet hozzanak létre, valamint minimalizálják a szintetizált és a bemeneti kép közötti különbséget.
	 Az ábrán \ref{fig:deca} látható módon, egy $E_{c}$ kódolót tanítanak be, amely egy ResNet50 \cite{liwen} hálózatból, és egy azt követő teljesen összekapcsolt rétegből áll, egy alacsony dimenziós látens kód regressziója céljából. Ez a látens kód tartalmazza a $\omega$ (identitás), $\psi$ (kifejezés), $\theta$ (póz) FLAME \cite{flame} paramétereket(azaz reprezentálja a durva geometriát), az albedó együtthatókat $\alpha$, a kamera $c$ és a megvilágítási $I$ paramétereket.\\
	 
 \subsubsection{Dekódoló}
 	 
 	A dekódoló hálózat egy részletes $UV$ elmozdulási térképpel $D$ egészíti
 	ki a durva $FLAME$ geometriát. A durva rekonstrukcióhoz hasonlóan
 	egy $E_{d}$ kódolót tanítanak be (amelynek architektúrája megegyezik az $E_{c}$
 	felépítésével), hogy az $I$ 2D-s képből egy 128 dimenziós látens kódot $\delta$
 	készítsen, amely az alanyspecifikus részleteket reprezentálja. A látens kódot $\delta$
 	ezután a $FLAME$ $\psi$ kifejezés és állkapocs póz $\theta_{jaw}$ paramétereivel kapcsolják
 	össze, majd $F_{d}$ az imént említett paraméterekből előállítja $D$-t. $F_{d}$ a látens kódot $\delta$ felhasználva szabályozza a statikus személyspecifikus részleteket. Kihasználja a durva rekonstrukcióból kapott kifejezés $\psi$, és az állkapocs $\theta_{jaw}$ paramétereket a dinamikus, kifejezésektől függő ráncok részleteinek rögzítése érdekében. A rendereléshez $D$-t normáltérképpé alakítják.
 	 
 \subsubsection{Részletkonzisztencia veszteség}
	 
	 \begin{figure}[h]	
	 	\centering
	 	\includegraphics[width=1\linewidth]{ldetail}
	 	\caption{Részletkonzisztencia veszteség \\
	 		Forrás:\cite{deca}}
        \label{fig:ldetail}
	 \end{figure}
 
 	Yao Feng et al. az identitás-függő és a kifejezésektől függő részletek
 	szétválasztása érdekében egy új részletkonzisztencia veszteség függvényt
 	javasolnak. A metódus nélkül a személyspecifikus látens kód $\delta$ rögzíti az iden-
 	titástól és a kifejezésektől függő részleteket. Ebből kifolyólag a rekonstruált
 	részletek nem repozicionálhatóak a FLAME állkapocs póz $\theta_{jaw}$ és arckifejezés $\psi$
 	paramétereinek megváltoztatásával.
 	Amennyiben adott két kép $I_{i}$ és $I_{j}$ ugyanarról az alanyról ($c_{i} = c{j}$ ), a
 	veszteséget a következőképpen határozzuk meg:

    \begin{equation*}
    L_{dc} = L_{detail}(I_{i}, R(M (\beta_{i}, \theta_{i}, \psi_{i}), A(\alpha_{i}), F_{d}(\delta_{j} , \psi_{i}, \theta_{jaw,i}), l_{i}, c_{i}))
    \end{equation*}
   
 	, ahol $\beta_{i},$ $\theta_{i},$ $\theta_{jaw,i},$ $\alpha_{i},$ és $c_{i}$ $I_{i}$ paraméterei, valamint $\delta_{j}$ $I_{j}$ részletkódja.
 	
 	\subsubsection{Tanítás}
 	
 	Ebben az alfejezetben a(z) \ref{fig:deca}. ábrán szemléltetett $DECA$ modellt
 	vizsgáljuk meg.
 	A tanítás során (bal oldali doboz) a $DECA$ minden egyes képhez
 	az arc alakjának rekonstruálásához szükséges paramétereket becsli meg az
 	alakkonzisztencia információ segítségével (a kék nyilakat követve), majd
 	a részletkonzisztenica-információ (a piros nyilakat követve) kihasználásával
 	megtanul egy kifejezésfüggő elmozdulási modellt. A sárga doboz tartalmazza
 	az elmozdulási konzisztencia-veszteséget, amelyet részletesebben a(z) \ref{fig:ldetail}. ábra
 	szemléltet.
 	A tanítás után a $DECA$ animál egy arcot (\ref{fig:deca}. ábra, jobb oldali doboz)
 	a rekonstruált forrásidentitás alakjának, fejpózának, részletkódjának
 	valamint a forráskifejezés állkapocs pózának és arckifejezési paramétereinek
 	kombinálásával, annak érdekében, hogy egy animált durva alakot és egy
 	animált elmozdulási térképet kapjon. A modell kimenete egy animált
 	részletes alakzat.
 	
 	\subsubsection{Adathalmazok}
 	
 	A $DECA$-t három nyilvánosan elérhető adathalmazon tanítják:
 	\begin{itemize}
 		\item VGGFACE2
 		\item BUPT-Balancedface
 		\item VoxCeleb2
 	\end{itemize}
 
 	A VGGFace2 több, mint 8 ezer alany képeit tartalmazza, átlagosan több,
 	mint 350 képpel alanyonként. A BUPT-Balancedface 7 ezer képet kínál
 	etnikumonként, és a VoxCeleb2 pedig 145 ezer videót tartalmaz 6 ezer
 	különböző alanyról. összességében a DECA-t 2 millió képpel tanították
 	be.
 	
 	\subsection{FOCUS}
 	
 	Chunlu Li et. al \cite{focus} megközelítése a korábbi munkákhoz képest azért
 	különleges mert, a 3D-s arcok rekonstrukcióját és a kitakarások szegmentálását
 	együttesen végzi. Ráadásul, az általuk fejlesztett pipeline csak gyenge felügyelet mellett tanul, és nincsen szüksége annotációkra a különböző típusú
 	okklúziókhoz.
 	Ezenkivül, az általuk használt arc autoencoder lehetővé teszi az arcmodell hatékonyabb illesztését. Ahhoz, hogy növelni tudják a megvilágítással és
 	más tényezőkkel szembeni robosztusságot, implementáltak egy úgynevezett
 	perceptuális költségfüggvényt, amellyel a szegmentáló hálózat képes a szemantikus jellemzők helyett csak a független pixeleken keresztül gondolkodni.
 	
 	\begin{figure}[h]	
 		\centering
 		\includegraphics[width=1\linewidth]{focus}
 		\caption{Chunlu Li et al. által javasolt megközelítés felépítése.
 			Forrás:\cite{focus}}
        \label{fig:focus}
 	\end{figure}
 	
 	A fenti ábrán láthatjuk a $FOCUS$ hálózat felépítését.
 	Adott egy $I_{T}$ bemeneti kép, a rekonstrukciós hálózat, $R$, megbecsüli a látens
 	paramétereket és ezt követően egy olyan $I_{R}$ képet állít elő, amely csak az
 	arcot tartalmazza. Ezután az $I_{T}$ és $I_{R}$ képeket betápláljuk az $S$ szegmentáló
 	hálózatba, amely megjósolja az $M$ szegmentációs maszkot. A szaggatott
 	vonalak azt mutatják, hogy $M$-et arra használják, hogy az $I_{T}$ és $I_{R}$ képekben
 	a becsült kitakaró tényezőket kiszűrjék a képből, ezáltal összerakott kitakarás mentes képeket
 	kapnak, nevezetesen $I_{T}\bigodot M$ és $I_{R}\bigodot M$ .
 	Megfigyelhetjük, hogy Chunlu Li et. al nagy hangsúlyt fektettek bele a
 	robosztus arcrekonstrukcióra kitakarások mellet. A munkánk szempontjából
 	azért fontos, mert az arcot kitakaró tényezők mindenütt jelen vannak. Ezért is választottuk
 	a $FOCUS$-t, mert nekik sikerült egy speciális modellt implementálni, ami
 	képes kezelni a kitakarásokat anélkül, hogy szükséges lenne nagy mennyiségű
 	adatra vagy olyan erőforrásra, amihez nincs hozzáférésünk.
 	A továbbiakban részletesebben megvizsgáljuk a $FOCUS$ építőelemeit és
 	együttműködésüket.
 	
 	Ahogy, már korábban is említve volt, a $FOCUS$ célja 3D-s
 	arcrekonstrukció egyetlen képből, súlyos kitakarások esetén is. Ezen kihívást
 	jelentő probléma megoldásához egy modellalapú arc autokódolót, $R$-t, és
 	egy szegmentáló hálózatot, $S$-t implementáltak, ahogyan az a fenti ábrán is
 	szemléltetve van.
 	
 	Az arc rekonstrukciójához a szegmentációs maszk a modellillesztés során
 	kivágja a becsült kitakarásokat, így a rekonstrukciós hálózatot robosztussá
 	teszi a kitakarásokkal szemben. A szegmentáláshoz a rekonstruált eredmény
 	referenciaként szolgál, növelve a szegmentálás pontosságát.
 	
 	Ebben a szakaszban megvizsgáljuk hogyan működik a két hálózat,
 	hogyan kapcsolódnak egymáshoz és milyen előnyöket nyújtanak
 	egymás számára.
 	
 	\subsubsection{Modellalapú autoencoder}
 	A modellalapú arc autokódoló, $R$, várhatóan rekonstruálja a teljes arc
 	megjelenését a látható arctartományokból a képen, $I_{T}$-n. Ez egy kódolóból, grafikus renderelőből, és egy dekódolóból áll. A kódoló megbecsüli a látens
 	parmétereket $\theta = [\alpha, \gamma, \phi, c] \in R^{257}$, azaz a 3D alak $\alpha \in R^{144}$, a 3DMM
 	textúrája $\gamma ∈ R^{80}$, a megvilágítás $\phi ∈ R^{27}$, és a jelenet kamera paraméterei
 	$c ∈ R^{6}$. Adott látens parméterekkel a dekódoló a bemeneti képen látható
 	arcképét állítja elő $I_{R} = R(\Theta)$. Majd ehhez egy olyan felügyelet nélküli szegmentáló hálózatot vezetnek be, melynek kimenetelét a modellillesztés során
 	a kitakarások elfedésére lehet használni, és így az autokódolót robosztussá
 	teszi a kitakarásokkal szemben.
 	
 	\subsubsection{Szegmentációs hálózat}
 	A szegmentáló hálózat, $S$, veszi az $I_{T}$ képet és a szintetizált képet, $I_{R}$-t, bemenetként, és megjósolja a bináris maszkot, $M = S(I_{T} , I_{R}$, annak
 	leírására, hogy egy pixel az arcot ábrázolja-e $(1)$ vagy nem $(0)$. Mivel az $I_R$ tartalmazza a becsült arcot, előzetes tudást biztosít a szegmentáló hálózatnak
 	́es segíti a becslést.
 	
 	Az arc autokódoló és a szegmentáló hálózat a tanítás során össze vannak kapcsolva olyan módon, hogy egy szinergikus hatást váltanak ki, ami a szegmentálást pontosabbá teszi és a rekonstrukciót robosztussabbá teszi kitakarások jelenlétében.
 	
 	\subsubsection{Tanítás}
 	Az arc autokódoló és a szegmentáló hálózat kölcsönös függőségei miatt egy $Expectation − Maximization(EM)$ típusú stratégiát alkalmaztak,
 	ahol a két hálózatot váltakozva tanították be. Ez lehetővé tette a stabil
 	konvergenciát a betanítási folyamat során. Mint más EM típusú tanítási
 	stratégiákhoz hasonlóan, a tanítási folyamatuk a modell paraméterinek
 	durva inicializálásával kezdődik, amely felügyelet nélküli módon történik.
 	
 	A szegmentáló hálózat tanításakor az arc autokódoló paraméterei
 	rögzítettek és csak a szegmentáló hálózatot optimalizálják. Alapvetően négy költségfüggvényt javasolnak, amelyek
 	kikényszerítik a képek közötti hansolóságokat. A költségfüggvények dolga
 	hogy, eldöntse egy adott pixelről hogy az arc része vagy sem. Ezek
    perceptuális szinten vagy pixel szinten dolgoznak, hogy teljes mértékben
 	kihasználják a vizuális nyomokat.
 	
 	Betanítás során a szegmentáló hálózat feladata, hogy egyensúlyt
 	keressen az olyan képpontok elvetése között, amelyeket az autokódoló nem
 	tud jól értelmezni és az olyan képpontok megőrzése között, amelyek fontosak
 	a bemeneti kép és az előállított arc perceptuális reprezentációjának megőrzése
 	́erdekében. Ezáltal nincsen szükség a kitakarások felügyeletére.
 	
 	Az autkódoló betanítása során, tovább optimalizálták a kódoló paramétereit, közben a szegmentáló hálózat rögzítve van. Az autokódolóhoz az alábbi költségfüggvények tartoznak:

    \begin{equation*}
    L_{pixel} = \parallel (I_{T} − I_{R}) \bigodot M \parallel _{2}^{2} 
    \end{equation*}
    \begin{equation*}
    L_{per} = \cos(F(I_{T}), F(I_{R}))    
    \end{equation*}
    \begin{equation*}
    L_{lm} = \parallel lm_{T} - lm_{R} \parallel _{2}^{2}  
    \end{equation*}

 	\subsubsection{Adathalmazok}
 	Az általuk felhasznált adatbázisok a CelebA-HQ és az AR adathalmaz.
 	Ezek segítségével értékelik az illesztés és az arcszegmentlás hatékonyságát.
 	Az alakrekonstrukció kiértékelésére a NoW adatbázis
 	részhalmazait használták.
 	
 	\begin{figure}[h]	
 		\centering
 		\includegraphics[width=1\linewidth]{now}
 		\label{fig:now}
 		\caption{NoW Challenge benchmark eredményei
 			Forrás: https://github.com/unibas-gravis/Occlusion-Robust-MoFA}
 	\end{figure}
 	
 	\subsection{Értékelés}
 	
 	Mint láthatjuk a fent említett megközelítések mind kiváló eredményeket
 	nyújtanak, de megfigyelhetjük hogy a két munkának a szerzői teljesen
 	különböző motivációval rendelkeztek.
 	A $DECA$ főbb motivációja az emberi arc részleteinek megőrzése valamint az arc realisztikus animálhatósága. A
 	$FOCUS$ célja pedig egy gyors modell kialakítása volt, amely korábbi
 	munkákhoz képest jobban kezeli a kitakarásokat. A mi célunk, egy olyan
 	animálható modell kialakítása, amely képes megőrízni a részleteket. Emellett képes konzisztens mükődést nyújtani súlyos kitakarások jelenlétében is.
 	
 	Tehát a tervezett modell, amit a későbbiekben részletesebben
 	megvizsgálunk kettő egymást támogató hálózatból áll. Egyik fő épitőeleme a
    $DECA$ alapján készített rekonstrukciós hálózat. A másik,
 	a $FOCUS$ megközelítésében implementált szegmentációs hálózat. E két
 	hálózaton egy EM típusú stratégiát alkalmazunk a tanítási folyamat
 	során.
 	
 
	 \section{3D arcmodell konstruálása}
	 \label{3d}
	 \cite{survey} A 3D-s arcok legelterjedtebb statisztikai modellje a 3D Morphable Models (3DMM), amelyet Blanz és Vetter \cite{blanzvetter} mutatott be a közösségnek. \textit{Bernhard et al.} \cite{3dmm} munkája alapján a 3D Morphable Face Model egy generatív modell az arcformára
	 és a megjelenés modellje, amely két kulcsfontosságú ötleten alapul:
	 
	  Először is, minden arc
	 sűrű pont-pont megfeleltetésben van, amelyet általában egy regisztrációs eljárás során egy sor példaarcon állítanak elő, majd
	 a további feldolgozási lépések során is megmarad.Ennek a megfeleltetésnek köszönhetően az arcok lineáris kombinációi definiálhatók egy értelmes módon, morfológiailag valósághű arcokat (morfokat) létrehozva.
	 
	 
	 A második ötlet az arc alakjának és színének szétválasztása, és ezek függetlenítése a külső tényezőktől, például a megvilágítástól és a kamera paraméterektől.
	 
	  A \textit{morphable} modell magában foglalhat egy statisztikai modellt
	 az arcok eloszlásáról, amely egy főkomponens elemzés az eredeti munkában.
  Egy lineáris
alteret határoznak meg az alakzat és a textúra reprezentálására főkomponens elemzés \cite{PCA} segítségével, és bemutatják, hogyan lehet a modellt az adatokra illeszteni. 

	 \subsection{Arcképfelvétel}
	  Minden 3D statisztikai arcmodell legfontosabb összetevője a 3D alakzatok reprezentatív készlete a megfelelő megjelenési adatokkal együtt. A mintakészlet létrehozásának tipikus módja, hogy az adatokat a valós világból kapjuk meg. Ebben a szakaszban rövid áttekintést adunk a különböző megközelítésekről, amelyeket az arcadatok, valamint az arcképek adatainak megszerzésére használatosak \cite{3dmm}.
	  
	 A bemeneti adathalmazok létrehozása a 3DMM-ek számára kontrollált körülmények között történő felvételre korlátozódnak szemben a nagyobb kihívást jelentő kontrollálatlan felvételekkel.
	 
	 Megjegyzendő, hogy a kontrollált 3D arcfelvétel nem mindig szükséges. Voltak kísérletek arra, hogy a 3DMM-eket közvetlenül képekből tanulják meg. Például Cashman és Fitzgibbon munkája 2012-ben \cite{dolphins} és a legmodernebb mélytanuláson (\textit{deep learning}) alapuló módszerek egyszerre tanulnak 3DMM-et és regresszió-alapú illesztést 2D-s tanítási adatokból.
	 
	 \subsection{Alakfelvétel}
	 A háromdimenziós forma vitathatatlanul a 3DMM legfontosabb összetevője \cite{3dmm}. Az alakzat ábrázolásának kérdése
	 a 3DMM-ek összefüggésében nem került széles körben figyelembe vételre.
	 
	  Messze a
	 leggyakrabban használt reprezentáció a háromszögháló. Vannak ritka kivételek, de ebben a munkában ezeket nem fogjuk megemlíteni.
	 
	  A háromszöghálós reprezentáció sűrű megfeleltetéssel megköveteli, hogy minden minta azonos topológiát mutasson, és hogy a csúcsok minden mintán ugyanazt a szemantikai pontot kódolják. A minták közötti megfelelés megállapítása önmagában is kihívást jelentő téma. Ebben a szakaszban a nyers 3D adatokra összpontosítunk.
	
	
	\subsubsection{Statisztika alapú modell illesztési módszerek}
	A statisztikai 3D arcmodell \cite{survey} a legnépszerűbb módszer az előzetes információ hozzáadására, mivel ezek kódolják az arc geometriai variációit, esetleg a megjelenéssel együtt.
	
	 Az ilyen modellek tartalmaznak egy átlagos arcot, valamint annak geometriájának és az arcmintázatának a variációit és a megjelenését.
	 
	  3D arcmodell illesztése fényképre
	a modell paraméterein kívül,
	a 3D póz és a megvilágítás meghatározásával történik úgy, hogy
	az eredményül kapott 3D-s arc képsíkjába történő vetülete
	a lehető legjobban hasonlítson az adott képhez.
	
	\subsubsection{Geometriai módszerekhez}
	A geometriai módszerek \cite{3dmm} közvetlenül becslik egy alakzat 3D-s koordinátáit vagy ugyanazon felület megfigyelésével
	két vagy több nézőpontból (ebben az esetben a kihívás a megfelelő pontok azonosítása a képek között), vagy pedig egy vetített minta megfigyelésével (ebben az esetben a kihívás az ismert minta és a róla készült vetület kép közötti megfeleltetés azonosítása).
	
	 A módszerek vagy aktívnak tekinthetők, azaz fényt
	vagy más jeleket sugároznak, vagy passzívak.
	
	
	A lézerszkennerek, a \textit{Time-of-Flight} érzékelők és a strukturált fényrendszerek \textit{aktív} rendszerek, míg a több nézetből álló fotogrammetria \textit{passzív} alternatíva.
	
	\subsubsection{Fotometrikus módszerek}
	A fotometrikus módszerek \cite{3dmm} jellemzően a felület orientációját becslik, amelyből integrálással vissza lehet nyerni a 3D alakot.
	
	 A kihívás itt az, hogy olyan modelleket válasszunk, amelyek pontosan megragadják a felszín reflexiós tulajdonságait, valamint elegendő mérési eredményt kapjunk ahhoz, hogy e modellek invertálása jól megoldható legyen. 
	 
	 A geometriai módszerekhez képest a fotometriai módszerek
	 jellemzően nagyobb alaki részletességet kínálnak, és nem függnek a
	 összeilleszthető jellemzők meglététől
	(tehát sima, jellegtelen felületek esetén is alkalmazhatóak), de gyakran szenvednek alacsony frekvenciájú torzításoktól a rekonstruált képekben
	a fényvisszaverő képesség és a megvilágítás modellezési hibái miatt.
	
	
	A fotometrikus sztereó \cite{photometric} a felszín normálisa adja meg minden egyes képpontnál a jelenet rögzített pozícióból történő megfigyelésével, legalább három különböző megvilágítási körülmény között.
	
	 A szükséges képkockák számát spektrális multiplexálással lehet csökkenteni \cite{multiplex}.
	
	\subsubsection{Hibrid módszerek}
	A hibrid módszerek \cite{3dmm} a
	geometriai és a fotometriai módszerek kombinációja. 
	
	Csökkentik a
	a fotometriai módszereknél jellemzően jelenlévő alacsony frekvenciájú torzítást, és
	növelik a nagyfrekvenciájú részleteket a geometriai módszerekhez képest. 
	
	Diego Nehab \textit{et al}. \cite{hibrid} javaslata egy olyan módszer, amely helymeghatározó információk alacsony frekvenciáját egyesíti a felszíni normálisok magas frekvenciájával. 
	A módszer különösen hatékony, mivel csak egy lineáris egyenletrendszer megoldása szükséges. 

    \subsection{FLAME modell}

    Mint ahogyan már említettük, Blanz és Vetter javasolták az első általános 3D modellt \cite{3dmm}, ami szkennelt adatokból tanult. Meghatároztak egy lineáris alteret az alak és a textúra reprezentálására főkomponens analizis (PCA) segitségével. Illetve bemutatják hogyan kell a modellt az adatokhoz illeszteni. A modell 200 fiatal, többnyire kaukázusi felnőtt fejének szkenneléséből épült fel. A modellnek jelentős hatása volt mivel nyilvánosan elérhető további kutási munkákhoz, mint például a Basel Face Model.

    A FLAME modell egy statisztikai fejmodell \cite{flame}, ami pontosabb és kifejezőbb mint a korábbi fej- és arcmodellek, miközben kompatibilis marad a szabványos grafikus szoftverekkel.
    A már meglévő modellekkel ellentétben a FLAME explicit módon modellezi a fej tartását és a szemgolyó forgását.

    A FLAME egyesíti a különálló lináris identitásalak és kifejezés tereket $linear$ $blend$ $skinning$-gel (LBS) és a pózfüggő korrektív $blendshape$ alakzatokat, annak érdekében, hogy
    a nyak, az állkapocs és a szemgolyók mozgathatóak legyenek. Adott arc identitás $\beta ∈ R^{|\beta|}$, póz $\theta \in R^{3k+3}$ (ahol $k = 4$ a nyak, állkapocs, és szemgolyók ízületeinek száma), és arckifejezés $\psi \in R^{|\psi|}$ paraméterek mellett, a FLAME egy $n = 5023 $ csúcspontot tartalmazó archálót ad kimenetül.
    A modell a következőképpen van definiálva: 
    \begin{equation*}
        M (\beta, \theta, \psi) = W (T_{p}(\beta, \theta, \psi), J(\beta), \theta, W)
    \end{equation*}
    ahol, a $blendskinning$ függvény $W (T, J, θ, W)$ elforgatja a 
    $T \in R^{3n}$ csúcsait a $J \in R^{3k}$ ízületek körül, lineárisan finomítva a $W \in R^{k\times n}$
    keverési súlyokkal. A $J$ ízületi helyek a $\beta$ identitás függvényeként definiálhatók.
    Továbbá, 
    \begin{equation*}
        T_{p}(\beta, \theta, \psi) = T + B_{S}(\beta, S) + B_{P}(\theta, P) + B_{E}(\psi, E)
    \end{equation*}
     jelöli a $T$ minta átlagát ”nullpózban” a hozzáadott alak blendshape-ekkel $B_{S} (\beta, S) : R^{|\beta|} \Rightarrow R^{3n}$, pózkorrekciókkal $B_{P}(\theta, P) : R^{3k+3} \Rightarrow R^{3n}$, valamint kifejezés blendshape-ekkel $B_{E}(\psi, E) : R^{|\psi|} \Rightarrow R^{3n}$, a megtanult identitás-, póz- és kifejezésalapokkal (lineáris alterekkel) $S, P$ és $E$. \\

    A legtöbb korábbi módszer figyelmen kívül hagyta a szemeket a
    hozzáigazítás során. Ez torzítja a szemhéjakat és jelentős fotometriai hibákat okoz a szemek régiójában. Következésképpen szemgolyókat adtak hozzá a hálóhoz és bizonyították, hogy ez segíti az igazítási folyamatot.

    Egyik fő szempont, hogy kutatásunkban a FLAME modellt használjuk, az hogy a FLAME betanított modelljeit kutatási célokra nyilvánosan hozzáférhetővé tették, valamint a modell segítségével animálható 3D arcok készíthetőek.
	
	\section{Neurális hálózatok}
	\subsection{Neurális hálózat}
	\label{NN}
	Az emberi agy bizonyítja a hatalmas neurális hálózatok \cite{ann} létezését, amelyek sikeresen végeznek el kognitív, észlelési és irányítási feladatokat. Ilyen számításigényes feladat például az arcfelismerés, a beszéd és a testmozgás. Az agy hatékonyan kihasználja a masszív párhuzamosságot, számítási struktúrája nagymértékben párhuzamos, és jó információfeldolgozási képességgel rendelkezik.
	
	Az emberi agy több, mint 10 milliárd egymással összefüggő neuron gyűjteménye. Mindegyik neuron egy sejt [1. ábra], amely biokémiai reakciókat használ az információ fogadáshoz, feldolgozáshoz és továbbításhoz.
	
	Az idegrostok faszerű hálózatai, az úgynevezett dendritek kapcsolódnak a sejttesthez, ahol a sejtmag található. A sejttestből egyetlen hosszú rost nyúlik, melyet \textit{axon}nak neveznek. Az \textit{axon} szálakra és alszálakra ágazik, majd szinapszisain keresztül kapcsolódik más neuronokhoz. Az itt létrejövő szinaptikus kapcsolat erőssége határozza meg az emberi agy tanulását\cite{ann} .
	
	A jelek átvitele egyik neuronról a másikra a szinapszisoknál egy összetett kémiai folyamat, amelyben specifikus közvetítő anyagok szabadulnak fel a kapcsolódási pont küldői oldalán. A folyamat hatására a fogadó sejtben emelkedik vagy csökken az elektromos feszültség\cite{ann}.
	\begin{figure}[h]	
		\centering
		\includegraphics[width=1\linewidth]{neuron1}
		\caption{Neuron felépítése. 
			Forrás:\cite{ann}}
	\end{figure}
	\newpage
	\subsection{Mesterséges neurális hálózatok}
	A mesterséges neurális hálózatok (ANN-artificial neural networks) az előző fejezetben [\autoref{NN}] említett fejlettebb élő szervezetek agyát alkotó neuronokról kapták nevüket. 
	
	Mint azt \textit{Abraham} \cite{ann} is említi, a neurális hálózatok alapvető feldolgozási elemeit mesterséges neuronoknak nevezzük, vagy csak egyszerűen neuronoknak vagy csomópontoknak (\textit{node}). A neuron leegyszerűsített matematikai modelljében a szinapszisok hatásai kapcsolati súlyokkal vannak reprezentálva, amelyek szabályozzák a bemeneti jelek hatását.
	
	 A neuronok által mutatott non-lineáris karakterisztikát átviteli függvény segítségével ábrázoljuk. A neuron impulzusát ezután a bemeneti jelek súlyozott összegeként számíthatjuk ki az átviteli függvénnyel transzformálva.
	 
	  Egy mesterséges neuron tanulási képessége a súlyok megfelelő beállításával érhető el egy választott tanító algoritmus felhasználásával.
	\newline
	\newpage
	Egy tipikus mesterséges neuron és egy többrétegű neurális hálózat modellezése a 2. ábrán látható. A 2. ábra szerint, ahogy a nyilak is mutatják, az $x_{1},...,x_{n}$ bemenetekről érkező jeláramlás egyirányúnak tekinthető, csakúgy mint a neuron kimeneti jelfolyama. A neuron kimeneti jelét \textit{O} a következő összefüggés adja:
	\begin{mdframed}
	\begin{align}
		&O = f(net) = f(\sum{j=1}^{n}w{j}x{j}) 
		\intertext{ahol $w{j}$ a súly vektor és $f(net)$ az \textit{aktivációs} (átviteli) függvény. A \textit{net} változó a súly és a bementi vektorok skaláris szorzataként definiálható,}
		&net = w^{T}x = w{1}x{1} + ... + w{n}x{n}
		\intertext{ahol T egy mátrix transzponálását jelöli, és a legegyszerűbb esetben a kimeneti érték \textit{O} kiszámítható, mint}
		&O = f(net) = 
		\begin{cases}
			1,; ha ; w^{T}x ; \geq ; \theta \
			0, \text{különben} \
		\end{cases} \
	\end{align}
	ahol $\theta$-t \textit{küszöbszintnek} (threshold) nevezzük. Ezt a típusú aktivációs függvényt \textit{küszöb aktivációs függvénynek} nevezzük.
	
	\end{mdframed}
	
	
	\begin{figure}[h]%
		\centering
		\subfloat[\centering Mesterséges neuron]{{\includegraphics[width=5cm]{artificialNeuron} }}%
		\qquad
		\subfloat[\centering Többrétegű neurális háló]{{\includegraphics[width=5cm]{multilayered} }}%
		\caption{Mesterséges neuron felépítése és egy többrétegű neurális háló \newline\centering Forrás: \cite{ann}}%
		\label{fig:fig2}%
	\end{figure}
	\newpage
	A \textit{küszöbfüggvényhez} hasonlóan más aktivációs függvényekkel is előállítható az adott neuron bemenetre kapott válasz. Ilyen függvények a 
	\begin{itemize}
		\item lineáris,
		\item szigmoid,
		\item tangens hiperbolikusz.
	\end{itemize}

	\begin{figure}[h]	
		\centering
		\includegraphics[width=1\linewidth]{fuggvenyek}
		\caption{(a) küszöbfüggvény, (b) lineáris, (c) szigmoid, (d) Gauss 
			\newline\centering Forrás:\cite{ann2}}
		\label{fuggvenyek}
	\end{figure}
	
	\begin{mdframed}
	Ma az egyik leggyakrabban használt aktivációs függvény a szigmoid \cite{ann4}, melyet a következő képlettel határoznak meg:
	\begin{align}
		&y = \frac{1}{1 + e^{-(a - \theta)b}}
	\end{align}
	ahol \textit{a} az aktiválás, \textit{b} pedig a görbe alakját szabályozza.
	\end{mdframed}
	
	\subsection{Neurális hálózat architektúra}
	
	Bár a mesterséges neuron működési elvei és 
	egyszerű szabályrendszere elsőre talán nem tűnik érdekesnek, azonban e modellek teljes potenciálja és számítási teljesítménye akkor kel életre, 
	amikor mesterséges neurális hálózatokká
	kezdjük őket összekapcsolni [2. ábra]. 
	Ezek a mesterséges neurális hálózatok 
	kihasználják az egyszerű tényt, 
	hogy a komplexitás néhány alapvető
	szabályból tud növekedni.
	
	A mesterséges neurális hálózatok 
	képesek komplex, valós problémák megoldására azáltal
	, hogy 
	alapvető építőelemeikben (\textit{mesterséges neuronok}) feldolgozzák az információt nemlineáris,
	elosztott, párhuzamos és lokális módon.
	
	Ahogy Krenker \textit{et al.} 
	\cite{krenker} is leírta, az egyes mesterséges 
	neuronok összekapcsolásának módját 
	\textit{topológiának}, \textit{architektúrának} 
	vagy \textit{gráfnak} nevezzük. A tény, 
	hogy az összekapcsolás
	számos lehetséges módon történhet több alkalmazható topológiát eredményez, amelyek két fő csoportra bonthatók. 
	
	A 4. ábra ezt a két topológiát mutatja. Az ábra bal oldala egy egyszerű feedforward topológiát ábrázol, ahol az információ a bemenetekről kimenetekre áramlik egyirányúan. Az ábra jobb oldalán pedig egy egyszerű rekurzív (\textit{recurrent}) topológiát ábrázol, ahol az információ egy része nem csak egy irányban áramlik a bemenetről a kimenetre, hanem ellenkező irányban is.

	Fontos megemlíteni, hogy a mesterséges neurális hálózat könnyebb kezelése és matematikai leírása érdekében az egyes neuronokat rétegekbe soroljuk. A 4. ábrán láthatjuk a bemeneti, a rejtett és a kimeneti réteget.
	\begin{figure}[h]	
		\centering
		\includegraphics[width=1\linewidth]{topologies}
		\caption{Feed-forward (FNN) és recurrent (RNN) \newline\centering  neurális hálózati topológiák. 
			Forrás:\cite{krenker}}
	\end{figure}

	A háló input rétegében minden neuron kapcsolatban áll a \textit{rejtett} (köztes) réteggel, így tovább adhatja a bemenetként kapott adatokat. A bemeneti réteg neuronjai súlyozott szinapszisokkal kapcsolódnak a belső rétegekhez.\\
	
	A mesterséges neurális hálózat 
	topológiájának kiválasztásával és 
	felépítésével még csak a feladataink 
	felét fejeztük be mielőtt a hálót az 
	adott probléma megoldására használhatnánk.
	Csakúgy, mint a biológiai neurális hálózatoknak
	is meg kell tanulniuk a megfelelő válaszokat különböző környezeti bemenetekre, a mesterséges neurális hálózatoknak is pontosan ezt kell tenniük.
	
	
	A következő lépés tehát, hogy \textit{betanítsuk} a mesterséges neurális hálózatot a helyes válaszokra.
	Erre négy lehetőségünk van:
	\begin{itemize}
		\item a \textit{supervised} (felügyelt)
		\item a(z) \textit{un-supervised} (felügyelet nélküli)
		\item a \textit{reinforcement} (megerősítéses) 
		\item és a hibrid
	\end{itemize}
	tanulás.
	
	 Függetlenül attól, hogy melyik módszert választjuk, a tanulás feladata, hogy a tanulási adatok alapján beállítsuk a súlyok és az előfeszítések értékeit, hogy minimalizáljuk a 
	költségfüggvényt.
	
	\subsection{Neurális hálók tanítása}
	
	A tanulási folyamat \cite{ann2} az ANN kontextusában a
	hálózat architektúrája és a kapcsolati súlyok frissítéseként értelmezhető annak érdekében, hogy a háló hatékonyan tudjon elvégezni egy adott feladatot.
	A hálózatnak a rendelkezésre álló tanító mintákból kell megtanulnia a kapcsolati súlyokat. A teljesítmény idővel javul a súlyok iteratív frissítésével.
	Az ANN-eket automatikus, példákból való tanulása teszi 
	vonzóvá és érdekessé. Szakértők által definiált szabályok helyett az ANN-ek a mögöttes szabályokat tanulják meg (pl. bemeneti-kimeneti kapcsolatokat) a megadott reprezentatív példák gyűjteményéből.
	
	\subsubsection{Felügyelt tanulás (\textit{supervised learning})}
	
	A felügyelt tanulás \cite{krenker} egy olyan gépi tanulási (\textit{machine learning}) technika, amely egy mesterséges neurális hálózat paramétereit tanítási
	adatokból állítja be. A tanuló ANN feladata, hogy beállítsa paramétereinek értékét bármely érvényes bemeneti értékre, miután látta a kimeneti értéket.
	A képzési adatok a bementi és a kívánt kimeneti értékek párjaiból állnak, amelyeket adatvektorokban ábrázolnak.
	
	
	A felügyelt tanulást \textit{klasszifikációnak} (\textit{classification}) is nevezhetjük, ahol \textit{osztályozók} (\textit{classifiers}) széles skálája áll rendelkezésünkre, amelyek mindegyikének megvannak az erősségei és gyengeségei.
	A megfelelő osztályozó (többrétegű perceptron, k-nearest neighbour algoritmus, Gauss-keverék modell, stb.. ) egy adott problémára való kiválasztása azonban inkább művészet, mint tudomány. A felügyelt tanulás egy
	adott problémájának megoldásához különböző lépéseket kell figyelembe venni \cite{krenker}.
	
	 Az első lépésben meg kell határoznunk a tanítási minták típusát. A második
	lépésben olyan képzési adathalmazt kell gyűjtenünk, amely kielégítően leírja az adott problémát.
	A harmadik lépésben az összegyűjtött képzési adathalmazt
	olyan formában kell leírnunk, amely érthető a kiválasztott ANN számára. A negyedik lépésben elvégezzük
	a tanulást, és a tanulás után tesztelhetjük a tanult ANN teljesítményét a teszt (validációs) adathalmazzal.
	A validációs adathalmaz olyan adatokból áll, amelyeket a tanulás során nem vezettünk be a mesterséges neurális hálózatba.
	
	\subsubsection{Felügyelet nélküli tanulás (\textit{unsupervised learning})}
	
	A felügyelet nélküli tanulás \cite{krenker} egy olyan gépi tanulási (\textit{machine learning}) technika, amely egy ANN paramétereit megadott adatok és egy minimalizálandó 
	költségfüggvény alapján állítja be. A költségfüggvény bármilyen függvény lehet, amit a feladat határoz meg.
	
	
	Felügyelet nélküli tanulást leginkább olyan alkalmazásokban használnak, amelyek a becslési problémák körébe tartoznak, mint például a statisztikai modellezés, filterezés és a klaszterezés. A felügyelet 
	nélküli tanulás során arra törekszünk, hogy meghatározzuk, hogyan szerveződnek az adatok. Ez a felügyelt és a megerősítéses tanulástól abban különbözik, hogy az ANN csak \textit{címkézetlen} (\textit{unlabeled}) mintákat kap. A felügyelet nélküli tanulás egyik gyakori formája a klaszterezés, ahol az adatokat hasonlóságuk alapján próbáljuk különböző klaszterekbe sorolni.
	
	\subsubsection{Megerősítéses tanulás (\textit{reinforcement learning})}
	
	A megerősítéses tanulás \cite{krenker} egy olyan gépi tanulási (\textit{machine learning}) technika, amely egy olyan
	mesterséges neurális hálózat paramétereit állítja be, ahol általában az adatok nincsenek előre megadva, hanem a környezettel való kölcsönhatásokból generálódnak. A megerősítéses tanulás azzal foglalkozik, hogy egy mesterséges neurális hálózatnak hogyan kellene viselkednie egy adott környezetben annak érdekében, hogy maximalizálja a hosszú távú 
	eredményeket.
	
	Miután a maximalizálandó visszatérési függvényt meghatároztuk, a megerősítéses tanulás számos algoritmust használ a maximális visszatérést eredményező szabályok (\textit{policy}) meghatározására. Az első lépésben egy naiv \textit{brute force} algoritmus kiszámítja a \textit{visszatérési függvény}t (\textit{return function}) minden lehetséges szabályhoz, és kiválasztja azt, amelyik a legnagyobb visszatéréssel rendelkezik. Ennek az algoritmusnak nyilvánvaló gyengesége a rendkívül magas vagy akár végtelen számú lehetséges szabály esetében rejlik. Ez a gyengeség kiküszöbölhető érték függvényes megközelítésekkel vagy közvetlen szabály becslésekkel. Az értékfüggvényes megközelítések megpróbálnak
	egy olyan szabályrendszert találni, amely maximalizálja a visszatérést.
	
	Ezek a módszerek konvergálnak a helyes becslésekhez egy rögzített szabály esetén, és az optimális szabály megtalálására is használhatóak. Az értékfüggvényes megközelítéshez hasonlóan a közvetlen szabály becslés is képes megtalálni az optimális szabályt.

    \subsubsection{Átviteli tanítás}
    
     A hagyományos gépi tanulási módszerek egyik feltételezése, hogy a tanítási és tesztelési adatok ugyanabból a tartományból származnak, így a bemeneti jellemzőtér és az adatok eloszlási jellemzői megegyeznek. Néhány valós gépi tanulási forgatókönyvben azonban ez a feltételezés nem áll fenn. Vannak olyan esetek, amikor a képzési adatok gyűjtése drága vagy nehézkes. Ezért nagy teljesítményű tanulók létrehozására van szükség, amelyeket különböző tartományokból könnyebben beszerezhető adatokkal tanítanak. Ezt a módszert átviteli tanulásnak nevezzük \cite{tl}.

     Az átviteli tanítás alapvető célja a modell fejlesztésének felgyorsítása egy meglévő modellből kiindulva és annak tovább hangolása a specifikus problémára.
 
	\subsection{Konvolúciós neurális hálózatok}
	\begin{figure}[h]	
		\centering
		\includegraphics[width=1\linewidth]{CNN}
		\caption{CNN(Convolutinal Neural Network)}
	\end{figure}
	
	A konvolúciós neurális hálózat (CNN) \cite{CNN} egy
	mély tanulási (\textit{deep learning}) megközelítés, amelyet széles körben használnak komplex problémák megoldására és felülmúlja a hagyományos gépi
	tanulási megközelítéseket.
	
	A konvolúciós neurális hálózat (CNN), gyakran ConvNet-nek is nevezik, mély feed-forward architektúrával rendelkezik, és jobban képes általánosítani, mint a teljesen összekapcsolt rétegekkel rendelkező hálózatok.
	
	A CNN, mint a hierarchikus jellemző detektorok biológiailag inspirált koncepciója, képes nagymértékben megtanulni
	absztrakt jellemzőket, és hatékonyan képes azonosítani az objektumokat.
	
	A CNN-t az alábbiak miatt tartják jobbnak más klasszikus modellekhez viszonyítva:
	
	Először is, a CNN-ek alkalmazásának legfőbb előnye a súlymegosztás koncepciójában rejlik
	, amelynek köszönhetően a betanítandó paraméterek száma jelentősen csökken, ami  jobb általánosításhoz vezet. 
	A kevesebb paraméter miatt a CNN egyszerűen betanítható, és nem szenved túlillesztéstől(overfitting).
	
	
	Másodszor, az osztályozási szakasz beépül a jellemző kinyerési szakaszba, mindkettő használ tanulási folyamatot.
	
	
	Harmadszor, a mesterséges neurális hálózat (ANN) általános modelljeinek felhasználásával nagy hálózatokat sokkal nehezebb megvalósítani,
	mint CNN-ben.
	
	
	A CNN-eket széles körben használják különböző területeken figyelemreméltó
	teljesítményüknek köszönhetően, mint például a képosztályozás, a tárgyak felismerése, az arcfelismerés, a beszéd
	felismerés, járműfelismerés stb.
	
	\subsection{A konvolúciós neurális hálózat általános modellje}
	
	\subsubsection{Általános modell}
	Az ANN általános modellje \cite{CNN} egyetlen bemeneti és kimeneti réteggel,
	valamint több rejtett réteggel rendelkezik.
	
	Egy bizonyos 
	neuron fogadja az X bemeneti vektort, és Y kimenetet állít elő azáltal,
	hogy valamilyen F függvényt hajt végre rajta az alábbi általános egyenlet alapján (5).
	\begin{mdframed}
	\begin{equation}
			F(X, W) = Y
	\end{equation}
	,ahol W a súlyvektor, amely a két neuron közötti összeköttetés erősségét jelöli két szomszédos réteg között.
 	\end{mdframed}

	A kapott súlyvektor most már felhasználható a képosztályozáshoz.
	
	Jelentős mennyiségű irodalom létezik a képek pixelalapú osztályozásával
	kapcsolatban, azonban az olyan kontextuális információk, mint a kép alakja vagy 
	a kép formája jobb eredményt adnak.
	
	A CNN a kontextuális információkon alapuló osztályozási képessége miatt kap egyre nagyobb figyelmet.\\
	
	
	A CNN általános modellje négy komponensből áll, nevezetesen 
	\begin{itemize}
		\item konvolúciós réteg
		\item pooling réteg
		\item aktivációs függvény
		\item teljesen összekapcsolt réteg
	\end{itemize}
	Az egyes komponensek működését az alábbi ábra szemlélteti.
	
	\begin{figure}[h]	
		\centering
		\includegraphics[width=1\linewidth]{element}
		\caption{\cite{CNN} A CNN elemi összetevői}
	\end{figure}

	
	\subsubsection{Konvolúciós réteg}
	
	\cite{CNN}Az osztályozandó képet a bemeneti rétegnek adjuk meg, a kimenet pedig az előre megjósolt osztálycímke, amelyet a képből kinyert jellemzők alapján számítunk ki.
	
	
	A következő rétegben lévő egyes neuronok az azt követő rétegben lévő neuronokhoz kapcsolódnak. Ezt a helyi korrelációt receptív mezőnek nevezzük.
	
	
	A bemeneti kép lokális jellemzőit a receptív mező segítségével nyerjük ki. Az előző rétegben egy adott régióhoz tartozó neuron receptív mezeje egy súlyvektort alkot, amely a sík minden pontján egyenlő marad, ahol a sík a következő rétegben lévő neuronokra utal. Mivel a síkban lévő neuronok azonos súlyokkal rendelkeznek, így a különböző helyeken előforduló hasonló jellemzők a bemeneti adatokon belül felismerhetők.
	
	\begin{figure}[h]	
		\centering
		\includegraphics[width=0.7\linewidth]{receptiv}
		\caption{\cite{CNN} Az adott neuron receptív mezeje a következő rétegben}
	\end{figure}
		\newpage
	A súlyvektor, más néven szűrő vagy kernel, a bemeneti vektoron csúszik át a \textit{featuremap} létrehozásához.
	A szűrő vízszintes és függőleges irányú csúsztatásának módszerét nevezzük konvolúciós műveletnek. A helyi receptív mező jelensége miatt a betanítható paraméterek száma jelentősen csökken.
	
	A következő rétegben az (i,j) helyhez tartozó $A_{ij}$ kimenet konvolúciós
	művelet alkalmazása után kerül kiszámításra az alábbi képlet segítségével:
	\begin{mdframed}
	\begin{align}
		a_{ij} = \sigma((W * X)_{ij} + b)
	\end{align}
	, ahol X a rétegnek adott bemenet, W a bemeneten áthaladó szűrő vagy kernel,
	b az eltolás, * a 
	a konvolúciós műveletet, és $\sigma$ a hálózatba bevezetett non-linearitást jelöli.
	\end{mdframed}
	
	\subsubsection{Összevonó réteg}

	A konvolúciós réteget összevonó (pooling) vagy 
	almintavételező (sub-sampling) \cite{CNN} réteg követi.
	A \textit{pooling} technika használatának fő előnye, hogy 
	jelentősen csökkenti a betanítható paraméterek számát,
	és bevezeti a fordítási invarianciát. 
	
	
	Az összevonás (\textit{pooling}) művelet elvégzéséhez kiválasztunk egy ablakot,
	és az abban az ablakban lévő bemeneti elemeket átadjuk
	egy összevonó (\textit{pooling}) függvénynek. a [8. ábrán] látható módon.
	
	\begin{figure}[h]	
		\centering
		\includegraphics[width=0.7\linewidth]{pooling}
		\caption{\cite{CNN} 2 x 2 ablak kiválasztásával végzett összevonási művelet}
	\end{figure}
	
	\newpage
	
	A pooling függvény egy másik kimeneti vektort generál.
	
	
	Létezik néhány összevonási technika, mint például az átlagos összevonás (\textit{average pooling}). 
	és a \textit{max-pooling}, amelyek közül a \textit{max-pooling} a leggyakrabban használt módszer,
	mely jelentősen csökkenti a leképezés méretét.
	
	
	A hibák kiszámítása során a hiba nem terjed vissza a győztes egységre.
	
	\subsubsection{Teljesen összekapcsolt réteg}
	
	A teljesen összekapcsolt réteg \cite{CNN} hasonló a hagyományos modellek teljesen összekapcsolt hálózatához.
	
	
	Az első
	fázis kimenete (a konvolúciót és a összevonást ismétlődően tartalmazza) a teljesen összekapcsolt rétegbe kerül, és a súlyvektor és bemeneti vektor pontproduktumát számoljuk ki a végeredmény kiszámítása érdekében.
	
	
	A \textit{gradiens süllyedés}, más néven kötegelt módú tanulás vagy offline algoritmus, csökkenti a költségfüggvényt a költség becslésével egy teljes tanítói adathalmaz felett, és a paramétereket csak egy korszak után frissíti, ahol egy korszak a teljes adathalmaz átfutásának felel meg.
	Ez globális minimumokat eredményez, de ha a képzési adathalmaz mérete nagy, akkor a hálózat tanításához szükséges idő
	jelentősen megnő. A költségfüggvény
	\\
	csökkentésének ezt a megközelítését felváltotta a \textit{sztochasztikus gradiens süllyedés}.
	\subsubsection{Aktivációs függvény}
	
	
	Számos szakirodalom létezik, amely a hagyományos gépi tanulási algoritmusokban
	szigmoid aktivációs függvényt használ.
	A nemlinearitás bevezetése érdekében a Rectified Linear Unit (ReLU) \cite{CNN} használata jobbnak bizonyult az előbbinél
	két fő tényező miatt. 
	
	Először is, a ReLU parciális deriváltjának kiszámítása egyszerű. 
	Másodszor, miközben figyelembe vesszük
	a képzési időt mint az egyik tényezőt, a telítődő nemlinearitások, mint a szigmoid lassabbak, mint a nem telítődő nemlinearitások, mint a ReLU.
	 Harmadszor, ReLU nem engedi, hogy a gradiensek eltűnjenek, de a ReLU hatékonysága romlik, ha nagy gradiens áramlik át a hálózaton, és a súly frissítése miatt a neuron nem aktiválódik, ami a \textit{Dying ReLU} problémához vezet, amely egy jelentős probléma. 
	 
	 Ez a probléma megoldható a \textit{Leaky ReLU} segítségével, ha $x>0$, a függvény aktiválódik.
	mint $f(x)= x$, ha pedig $x<0$, akkor a függvény $\alpha x$-ként aktiválódik, ahol $\alpha$ egy kis konstans.

    \subsection{Reziduális Neurális Hálózatok}
    
    \begin{figure}[h]	
 		\centering
 		\includegraphics[width=1\linewidth]{ResNet}
 		\caption{ResNet architektúrák felépítése. (felülről a 3.)
 			Forrás:\cite{resnet}}
        \label{fig:resnet}
 	\end{figure}
    
    A mélyebb neurális hálózatok nehezebben taníthatóak. Mivel amikor növeljük a rétegek számát, a mélytanulásban egy gyakori probléma merül fel, amit eltűnő/robbanó gradiensnek neveznek. Ennek hatására a gradiens 0 vagy túl nagy lesz. Így amikor növeljük a rétegek számát, a hibaarány is nő. 
    
    Ennek a problémának a megoldására He et al. \cite{resnet} bemutattak egy reziduális (maradékos) tanulási keretrendszert, amely megkönnyíti azon hálózatok tanítását, amelyek lényegesen mélyebbek a korábban használtakhoz képest. 

     A rétegeket kifejezetten úgy alakították át, hogy a rétegek a réteg bemeneteire hivatkozva maradványfüggvényeket tanulnak a nem hivatkozott függvények helyett. Ezek a reziduális hálózatok könnyebben optimalizálhatók, és pontosságot nyerhetnek az jelentősen megnövelt mélységből fakadóan.

    \newpage
    \subsubsection{Reziduális blokkok}
    
    
    \begin{figure}[h]	
 		\centering
 		\includegraphics[width=1\linewidth]{Residual-Block}
 		\caption{He et al. által javasolt reziduális blokk felépítése.
 			Forrás:\cite{resnet}}
        \label{fig:resblock}
 	\end{figure}
  
    Az eltűnő/explodálódó gradiens problémájának megoldására bevezették a Reziduális/Maradék blokkokat. A hálózatban úgynevezett kihagyásos kapcsolatok jönnek létre. A kihagyásos kapcsolat egy réteg aktivációit úgy kapcsolja össze a további rétegekkel, hogy közben néhány réteget kihagy. Ez egy reziduális blokkot képez. A reziduális hálózatok ezen reziduális blokkok egymásra halmozásával jönnek létre. Az ilyen típusú kihagyásos kapcsolatok hozzáadásának előnye, hogy ha bármelyik réteg károsítja az architektúra teljesítményét, akkor azt a regularizáció kihagyja. Ez tehát egy nagyon mély neurális hálózat tanítását eredményezi az eltűnő/robbanó gradiens okozta problémák nélkül. 

    \subsection{U-Net}

    Ebben a szekcióban Ronneberger et al. \cite{unet} munkája alapján bemutatjuk az U-Net architektúrát, amelyet a saját megvalósításunkban a szegmentációs maszk elkészítésére, optimalizálására használunk fel. 

    A konvolúciós hálózatok tipikus felhasználási területe az osztályozási feladatok, ahol
a kép kimenete egyetlen osztálycímke. Azonban számos vizuális feladatban,
különösen az orvosbiológiai képfeldolgozásban, a kívánt kimeneti eredménynek tartalmaznia kell
lokalizációt, azaz minden egyes képponthoz osztálycímkét kell rendelni. Továbbá,
több ezer tanító kép általában elérhetetlen az orvosbiológiai feladatokban.
Ezért Ciresan et al. \cite{ciresan} egy csúszóablakos elrendezést alkalmaztak, hogy prediktálják a
az egyes képpontok osztálycímkéjét az adott képpont körüli lokális régió bemenetként történő megadásával.

Ezt az architektúrát úgy módosították és bővítették, hogy
nagyon kevés tanítási képpel működjön, és pontosabb szegmentációkat eredményez.
Az alapötlet a szokásos szűkülő konvolúciós hálózat kiegészítése egymást követő rétegekkel, ahol a pooling operátorokat upsampling operátorok helyettesítik.
Ezért ezek a rétegek növelik a kimenet felbontását. A lokalizáció érdekében a magas
felbontású jellemzőket kombinálják a szűkülő útvonalról származó felskálázott kimenettel. Egy ezt követő konvolúciós réteg ezután megtanulhatja a kimenet precízebb összeállítását ezen információk alapján.

A felfelé mintavételezés
rész nagyszámú funkciócsatornával is rendelkezik, ami lehetővé teszi a hálózat számára, hogy
a kontextusinformációkat továbbítsa a magasabb felbontású rétegek felé. Ennek következtében,
az expanziós útvonal többé-kevésbé szimmetrikus az összehúzódási útvonalhoz képest, és
u alakú architektúrát eredményez.

\subsubsection{Architektúra}

A hálózat felépítését a(z) \ref{fig:unet}. ábra szemlélteti. A rendszer egy szűkülő
(bal oldal) és egy bővülő útvonalból (jobb oldal) áll. Az összehúzódó útvonal
a konvolúciós hálózatok tipikus architektúráját követi. 
Ez a következő lépések ismételt meghívásából áll:
    két 3x3-as konvolúció, melyeket egy-egy ReLU és egy 2x2 max pooling művelet követ. Minden lefelé mintavételezést a jellemzőcsatornák duplázása következik. 

    Az expanzív útvonal minden lépése a jellemzőtérkép felmintavételezéséből áll, amelyet egy 2x2-es konvolúció követ, amely megfelezi a jellemzőcsatornák számát, majd egy konkatenáció a megfelelően levágott jellemzőtérképpel a kontraháló útvonalról, és két 3x3-as konvolúció, amelyet egy-egy ReLU követ. A vágásra a határpixelek elvesztése miatt van szükség
minden egyes konvolúcióban. Az utolsó rétegben egy 1x1-es konvolúciót használnak minden egyes
64 komponensű jellemzővektor a kívánt számú osztályhoz való kötéséhez. Összességében a
hálózat 23 konvolúciós rétegből áll.
    
    \begin{figure}[h]	
 		\centering
 		\includegraphics[width=1\linewidth]{unet}
 		\caption{U-Net felépítése
 			Forrás:\cite{unet}}
        \label{fig:unet}
 	\end{figure}
   
	\section{Deep Learning módszerek}
	
	Az előző szakaszok [\nameref{3d}] 2D-ből 3D arc rekonstrukciós módszerei \textit{modelleket} használnak az előzetes tudás megtestesítésére \cite{survey}: a statisztikai modellillesztési módszerek tartalmaznak egy geometriai (és általában textúra) modellt, a fotometriai módszerek pedig a
	az arc fényvisszaverő képességét. 
	
	
	Ezzel szemben a mély tanulási módszerek
	közvetlenül tanulják meg a 2D kép és a 3D arc közötti leképezést, az előzetes ismeretek felhasználásával a betanított hálózatokban.
	
	
	Több indokból is előnyösebb mély tanulási módszerekkel dolgozni.\cite{3dmm}A modellezési oldalon a nemlineáris, mély reprezentációk használata lehetőséget nyújt arra, hogy felülmúljuk a klasszikus lineáris vagy multi-lineáris modelleket az általánosítás szempontjából, tömörség és specifikusság tekintetében \cite{styner}.
	
	
	A paraméter becslési oldalon ki tudjuk használni a mély hálózatok előnyeit, a gyorsaságot és a robusztusságot, hogy megbízható teljesítményt érjünk el a nem ellenőrzött képeken.
	
	\begin{figure}[h]	
		\centering
		\includegraphics[width=1\linewidth]{deep}
		\caption{A klasszikus analízis-szintézis és a mélytanulási megközelítések közötti kapcsolat. 
			Forrás:\cite{3dmm}}
	\end{figure}
	
	\newpage
	\subsection{Deep Face modellek}
	
	A hagyományos modellezési technikák célja, hogy
	az arc alakját, arckifejezését és megjelenését $w$ vektorként reprezentálják egy
	alacsony dimenziós latens térben $\mathbb{R}^d$ \cite{3dmm}. A vetítés (illetve rekonstrukció) ebből a latens térből lineáris vagy multi lineáris műveletekkel definiálható, és úgy is felfogható, mint a nagy-dimenziós információ kódolása (ill.
	dekódolása) a $\mathbb{R}^d$ térben.
	
	
	A mély tanulás új eszközt nyújt a 3DMM-ek építéséhez, amely nemlinearitást használ mind a
	a kódolóban és a dekódolóban. Az ilyen \textit{morphable} modellek létrehozása egy jelenleg nagyon aktív kutatási terület.
	Az alak és textúra modellezésre gyakran használt lineáris modellt felhasználva láthatjuk a \textit{deep learning} és a hagyományos módszerekkel tanult kódoló és dekódoló közötti kapcsolatot.
	
	
	A mély tanulás kontextusában egy ilyen lineáris modell
	az alábbi egyenletben formalizálva pontosan megfelel egy teljesen összekapcsolt rétegnek egy
	neurális hálózatban \cite{3dmm}.
	
	\begin{mdframed}
	\begin{equation}
		c(w) = \bar{c} + Ew 
	\end{equation}
		  ahol, $\bar{c}$ a képzési adatokra számított átlag, $E \in \mathbb{R}^{3n*d}$ egy olyan mátrix, amely tartalmazza a $d$ legdominánsabb sajátvektorjait \\
		  a formakülönbségekre $c_i - \bar{c_i}$ számított kovarianciamátrixban és
		$w$ az alacsony dimenziós alakparaméter-vektor.
	\end{mdframed}
	
	\cite{3dmm}Lényegében, a $w$ paramétervektora bemeneti jellemzők szerepét játssza, az $e_j$ főkomponensek pedig a súlyokét és az átlag $\bar{c}$ a torzítás.
	Ez úgy is felfogható, mint a dekódolás a latens paramétertérből a $c$ adattérbe. Vetítés a modellre
	hasonlóképpen tekinthető egy teljesen összekapcsolt réteggel történő kódolásnak,
	ahol a bemeneti jellemzők az adatok, a súlyok pedig a transzponált főkomponens mátrix sorai, az eltérések pedig adottak $-e^{T}_{j}\bar{c}$ által.
	
	
	 Az analógia lezárásaként a PCA (Principal Component Analysis) a kódoló és a dekódoló egyetlen rejtett réteggel rendelkező lineáris autokódolóvá (\textit{autoencoder}) történő kombinálásával, végezhető el.
	Egy ilyen autokódoló $d$ neuronokkal a
	rejtett rétegben egy olyan látens teret fog megtanulni, amelynek kiterjedése megegyezik a $d$
	dimenziós PCA-val, bár az ortogonalitás garanciája nélkül
	(ez megfelelő veszteségfüggvényekkel biztosítható).
	
	\subsection{Deep Face rekonstrukció}
	
	 A következőkben a mély neurális hálózatokon alapuló sűrű monokuláris arcrekonstrukció megközelítéseket tárgyaljuk. Megbeszéljük
	a felhasznált képzési adatokkal szemben támasztott követelményeket, valamint a különböző képzési
	stratégiákat. 
	
	
	Nézzük meg először közelebbről a rekonstrukciós problémát. Blanz és Vetter \cite{blanzvetter} egy optimalizációs megközelítésen alapuló parametrikus modell illesztésével, azaz a gradiens süllyedéssel, kezeli a monokuláris arc rekonstrukcióját. 
	
	
	 A mélytanulási megközelítések hasonló optimalizálási stratégiát követnek, de az optimalizálási probléma 
	"tesztelés" idején történő megoldása helyett, például egy paraméterregresszort képeznek ki egy nagyméretű képadathalmaz alapján \cite{3dmm}. A regresszor úgy értelmezhető, mint egy kódoló hálózat, amely egy 2D-s képet
	bemenetként fogad, és az alacsony dimenziós arcreprezentációt adja ki. 
	
	
	A
	kódolók kombinálhatók klasszikus arcmodelleken alapuló dekódolókkal,
	hogy végponttól-végpontig tartó kódoló-dekódoló architektúrákat hozzanak létre.
	Ez a módszertan széles körben elterjedt, és lehetővé teszi a klasszikus
	modellalapú és mélytanulási megközelítések ötvözését.
	
	\subsubsection{Felügyelt rekonstrukció}
	Felügyelt regressziós megközelítések
	párosított tanítási adatok segítségével, azaz egy monokuláris  képgyűjtemény
	és a megfelelő 3DMM paraméterei segítségével tanulnak \cite{3dmm}.
	
	
	Az egyik alapvető kérdés itt az, hogy hogyan lehet hatékonyan megszerezni az adatot egy ilyen felügyelt tanulási feladathoz. A következőkben
	kategorizáljuk a megközelítéseket a
	képzési adatok alapján. \\
	
	
	Az egyik lehetőség az lenne, hogy a felhasználók határozzák meg az adatot. Míg ez egy népszerű stratégia, amelyet gyakran alkalmaznak rekonstrukciós problémáknál \cite{saragih}, 
	a sűrű geometria, a megjelenés és a helyszín megvilágítás pontos meghatározása szinte megoldhatatlan.
	
	
	Hasonló megközelítést alkalmaztak például Olszewski \cite{olszewski} munkájában,ahol három professzionális animátor kézzel készítette el a \textit{blendshape} animációt egy videokliphez illesztve. A sűrű rekonstrukciós feladatokhoz egyes megközelítéseket ellenőrzött, több nézetből készült felvételek alapján tanítanak be.
	
	
	Így megkapható az adat egy több nézetből történő rekonstrukciós megközelítéssel, amelyet egy 3DMM illesztése követ. Ezáltal  megkapjuk a 3D adatot. Általában az alapadatok nagyon jó minőségűek,
	de a monokulárisan rögzített képek eloszlása nem
	egyezik meg az \textit{in-the-wild} adatokkal, ami általánosítási problémákhoz vezethet
	a tesztelés idejében.\\
	
	
	Anh Tuan Tran megközelítése monokuláris rekonstrukciót végez ugyanarról a személyről készült több képre, és kiszámít egy konszolidált arcazonosságot a 3DMM paraméterek egyszerű átlagolása alapján. \\
	
	
	Jelenleg a kutatóközösségben számos megközelítés szintetikus képzési adatokat használ tanításhoz, mivel könnyen beszerezhető és tökéletes annotációkkal rendelkeznek. 
	
	
	Adott egy 3DMM arc, véletlenszerű identifikációk és kifejezések mintavételezhetők a paramétertérben. 
	Majd,
	a modelleket véletlenszerű megvilágítási körülmények között és különböző nézőpontokból lehet renderelni a monokuláris képek létrehozásához. 
	
	
	A háttértámogatást gyakran alkalmazzák úgy, hogy a generált arcokat a valós világ sokféle hátterére renderelik. Mivel az összes paramétert ellenőrzik, ezért azok kifejezetten ismertek, és alapigazságként használhatók.
	
	
	Míg könnyen hozzájuthatunk a szintetikus képzési adatokhoz, gyakran van egy nagy tartományi rés
	a szintetikus és a valós világ képei között, ami súlyosan befolyásolja a
	a valós képekre való általánosítást. Például a hajat, az arcszőrzetet, a felsőtestet,
	vagy a száj belsejét gyakran egyáltalán nem modellezik. Az egyik lehetőség,
	a jövőben olyan modelleket használni, amelyek tartalmazzák ezeket, hogy ellensúlyozzuk ezt a problémát. 
	
	
	A valós és a szintetikus képzési adatok előnyeinek kihasználása érdekében számos jelenlegi megközelítést e két terület adatainak keverékével tanítanak. A remény itt az, hogy a megközelítés megtanulja kezelni a valós világi
	képeket, miközben a szintetikus tréning adatok tökéletes alapigazsága
	segítségével stabilizálható a tanulás.\\


	Ennek egy érdekes változata
	a tanítás önfelügyelt \textit{bootstrappelése}. A további megközelítéseket, amelyek tanítása nem igényel
	alapigazságadatokat a következő fejezetben vizsgáljuk meg.
	
	\subsubsection{Önfelügyelt rekonstrukció}
	A konvolúciós neurális hálózatok felügyelt tanítása annotált adathalmazt igényel. A legtöbb
	eddig tárgyalt módszer ilyen - szintetikus vagy valós - adathalmazokat használ.
	
	\cite{3dmm}
	A közelmúltban egyes megközelítések önfelügyeletet alkalmazó
	tanulást használtak, azaz 3D címkék nélküli, valós képi adathalmazokon történő tanítást.
	Ezt az analízis-szintézis és a mélytanulási technikák kombinációja tette lehetővé.
	
	
	Tewari \textit{et al.} \cite{tewari} egy modell-alapú kódoló-dekódoló architektúrát mutatott be, amely a
	a betanítható dekódert egy fix dekóderrel helyettesíti. Ez a dekóder a 3DMM paramétereket (látens kód)
	mint bemenet, amelyet a kódoló jelez, a 3DMM segítségével 3D-rekonstrukcióvá alakítja.
	Továbbá szintetikus képet készít a rekonstrukcióról egy differenciálható renderelő segítségével.
	A rendereléshez szükséges külső paramétereket szintén a kódoló jelzi előre. 
	
	
	Az alkalmazott veszteségfüggvény nagyon hasonlít az analízis-szintézisben használthoz \cite{3dmm}, ami fotometriai igazítást és statisztikai szabályozást foglal magába. Egy ilyen technikára úgy is gondolhatunk, mint egy közös
	\textit{analysis-by-synthesis} optimalizálási probléma egy nagyméretű tanulási
	adathalmazon, egyetlen kép helyett. Ez lehetővé teszi a paraméterregresszor képzését 3D felügyelet nélkül.
	
	\newpage
	\section{Megvalósítás}
	
	Ebben a fejezetben a projektünk redszertervét, gépi tanulási pipeline-ját, valamint kulcsfontosságú metódusait mutatjuk be részletesen.
	
	\subsection{Felhő alapú architektúra}
	
	\begin{figure}[h]	
		\centering
		\includegraphics[width=1\linewidth]{sysplan}
		\caption{ A rendszer felépítése}
	   \label{fig:sysplan}
 \end{figure}

	Ahogy korábban is említettük, a kitüzőtt céljaink között van, hogy a
	3D arc rekonstrukció és az arc analízis elérhető legyen felhőn keresztül.
	Továbbiakban megvizsgáljuk a rendszer felépítését illetve mükődését a
	fenti ábra segítségével. A(z) \ref{fig:sysplan}. ábrán látható, hogy 6 különböző szolgáltatást
	Minikube lokális klaszteren üzemeltetünk.

    \newpage
	\begin{mdframed}
		A minikube egy helyi Kubernetes, amellyel gyorsan tudunk létrehozni
		egy lokális klasztert, amely megkönnyíti a Kuberneteshez való tanulást
		́es fejlesztést
	\end{mdframed}

	A 6 különböző szolgáltatás az alábbiak:
	\begin{itemize}
		\item Frontend
		\item Backend
		\item Temporal.io szerver
		\item 3D arcrekonstrukciós modu
		\item Arcanalízis modul
		\item Adatbázis
	\end{itemize}

	A Temporal.io egy olyan technológia amely segítségével gyorsan és
	egyszerűen tudunk workflow-t implementálni. Ehhez szükséges a szerver,
	mert ott bonyolódik le egy workflow sikeres elvégzése, vagy hiba esetén
	biztosít egy dashboard-t amivel megtudjuk vizsgálni a hiba okát. Illetve,a
	workflow-ban implementáltuk a SAGA programozási mintát, amely kezeli
	hibák esetén az adatbázissal kapcsolatos műveleteket. Ezzel is robosztusabbá
	teszi a rendszert.
	
	Ha megnézzük a fenti ábrát, láthatjuk hogy, a workflow belépési pontja a HTTP kérés, aminek payload-ja, a kép egy célszemélyről, és amint a
	frontend-től megkapja a kérést a backend, az elindítja a workflow-t. A következő lépés hogy, a workflow metódusai egymás után meghívódnak.
	Végül a felhasználó visszakapja a rekonstruált képet, illetve a képen lévő személy akkori érzelmi állapotát és életkorát. Az arcrekonstrukciós és arc
	analízis moduljainkat Python nyelven implementáltuk, mivel mesterséges intelligenciával dolgozunk, a különböző nagymennyiségű Python könyvtár
	elérhetősége nagy mértékben megsegítette munkánkat.
	
	
	\newpage
    \subsection{Arcrekonstrukció}

    Ebben a fejezetben az arcrekonstrukciós hálózatunk felépitését és müködését vizsgáljuk meg és a hozzákapcsolodó technológiákat.

    \subsubsection{Tanítási adathalmazok}
	A rekonstrukciós modellünk nyilvánosan elérhető CELEBA adathalmazból tanul \cite{celeba}. A $CelebFaces Attributes Dataset$ (CelebA) egy nagyméretű arcattribútum adatkészlet, amely több mint 200 000 híresség képét tartalmazza, mindegyikhez 40 attribútum annotáció tartozik. Az adatállomány képei nagy pózvariációkat és háttérzavarokat fednek le. A CelebA nagy változatossággal, nagy mennyiségben és gazdag annotációkkal rendelkezik, többek között az alábbiakkal:

    \begin{itemize}
        \item 10 177 különböző személyazonosság
        \item 202 599 számú arckép
        \item 5 jellegzetes arcpont, képenként 40 bináris attribútum annotációja
    \end{itemize}

    
	\subsubsection{Adatok előkészítése}

   A valósághű 3D arcrekonstrukció elérése érdekében fontos, hogy az adatokat előkészítsük még a tanitási folyamat előtt. Ez a lépés a munkánkban az arc jellegzetes pontjainak detektálása majd $.csv$ fáljokba való kiírást jelent. Yao Feng et al. \cite{deca} megközelítését követve Bulat et. al. \cite{bulat} FAN modelljét használjuk 68 db 2D-s jellegzetes pont (landmark) detektálásához.
   
    \subsubsection{U-Net tanítási adatok generálása}

    A szegmentáló hálózat (U-Net) előtanításához adatokat kell generálnunk. Ehhez a folyamathoz mi a $face-toolbox-keras$ \url{https://github.com/shaoanlu/face_toolbox_keras} könyvtárat használjuk azon belül is a BiSeNet modellen alapuló modult \url{https://github.com/zllrunning/face-parsing.PyTorch} a szegmentációs maszk előállításához. A könyvtár által generált maszk azonban még nem megfelelő számunkra mivel nem csak az arcot veszi figyelembe, hanem a különböző kitakaró tényezőket is. Számunkra a maszkon csak az számit hogy, az adott pixel része-e az arcnak. Ebből adódóan a generált maszkot át kell alakítanunk olyan formábon, hogy a maszkon 1-es számmal jelölje azokat a pixeleket, amelyek az arc részei, valamint 0-val, ha az arc nem tartalmazza az adott képpontot. Eredményként egy szürkeárnyalatú maszkot kapunk. Ezt a folyamatot az egész tanítási adathalmazon végrehajtjuk. 
    
    \subsubsection{Differenciálható renderelő}

    Ebben a fejezetben Kato et al. \cite{diffrenderer} kutatása alapján bemutatjuk a differenciálható renderelő alapelvét.

    A legtöbb 3D becslési módszer a
felügyelt tanítási rendszerekre és költséges címkézésekre támaszkodnak, ami
a 3D megfigyelések összes paraméterének összegyűjtését jelentősen megnehezíti.
Az egyik
megközelítések egyike a grafikus renderelési folyamatok integrálása
a neurális hálózattal működő rendszerekbe. Ez lehetővé teszi az átalakítást és
a 3D becslések beépítését a 2D képi szintű bizonyítékokba.

A számítógépes grafikában a renderelés a geometria, a jelenet fényei és a kamera tulajdonságai alapján történő 3D-s jelenetek képének előállítását jelenti.

A differenciálható renderelés (DR) olyan technikák családját alkotja, amelyek a renderelési folyamat hasznos gradienseinek kinyerésével végponttól végpontig tartó optimalizálás céljából integrációt valósítanak meg. A renderelés differenciálásával a DR áthidalja a szakadékot.
a 2D és a 3D feldolgozási módszerek között, lehetővé téve a neurális hálózatok számára, hogy 2D-s vetületeken dolgozva optimalizálják a 3D-s entitásokat. Amint a(z) \ref{fig:diffrenderer}. ábrán látható, a 3D jelenet paramétereinek optimalizálása a gradiensek visszaterjedésével érhető el a renderelési kimenethez képest. 

Az általános 3D önfelügyeleti modell a renderelő réteg integrálásával a megjósolt jelenetparaméterekhez és a veszteség alkalmazásával a renderelt és a bemeneti kép különböző módokon történő összehasonlításával történik.

    \begin{figure}[h]	
		\centering
		\includegraphics[width=1\linewidth]{diffrenderer}
		\caption{Általános önfelügyeleti modell differenciálható rendereléssel.\\
                Forrás: \cite{diffrenderer}}
        \label{fig:diffrenderer}
	\end{figure}
 \newpage

\subsubsection{Tanítás}
    \begin{figure}[h]	
		\centering
		\includegraphics[width=1\linewidth]{pipelinehun}
		\caption{  A rekonstrukciós hálózat tanítási futószalagja.}
        \label{fig:pipeline}
	\end{figure}
 
	Az arcreskonstrukciós modellünket a(z) \ref{fig:pipeline}. ábrán szemléltetjük. A hálózatot PyTorch
	keretrendszerben fejlesztettük.
	A DECA módszerét követve a hálózatunk első lépése egy
	ResNet-50 modulból és egy teljesen összekapcsolt rétegből álló kódoló
	$E_{c}$, amely egy 2D-s kontrollálatlan környezetben készült képet kap bementként, majd visszaadja annak alacsony dimenzós látens kódját. A látens kód a $FLAME$
	paramétereket (durva geometriát) $\beta$ $\psi$ $\theta$, valamint az albedo együtthatókat
	$\alpha$, kamera $c$, és megvilágítási $l$ paramétereket tartalmazza.
	Az albedó paramétereket megkapja
	bemenetként a megjelenési modell, amely a Basel Face Model (BFM)
	lineáris albedó alterét alakítja át a $FLAME$ UV elrendezésébe,
	hogy kompatibilissé tegye azt $FLAME$-el A megvilágítási paramétereket
	a megvilágítási modell kapja meg bemenetként amely,
	a Spherical Harmonics (SH) alapú. A durva geometria
	paramétereit felhasználva a $FLAME$ modell egy durva alakzatot készít az
	arcról. A DECA által javasolt részletes dekódolóba a 128 db személyspecifikus jellemzőt betáplálva egy UV eltolódási térképet készítünk. A durva alakot és az eltolódási térképet felhasználva egy részletes alakzatot készítünk, amelyet átadva a megvilágítási modellel,
	az albedó térképpel, és a kamera paraméterekkel a differenciálható renderelőnek egy részletes rekonstruált textúrázott 3D-s fejet kapunk kimenetül.
	A $FOCUS$ megközelítéséhez hasonlóan,a szegmentáló hálózatunk átveszi
	a bemeneti képet és a hozzá tartozó részletes rekonstruált 3D-s fejet, majd
	megjósolja a bináris maszkot.

    \newpage
	\subsection{Arc analízis}

    \subsubsection{Tanítási adathalmazok}
    Az arc kifejezések klasszifikációjához a FER-2013 adathalmazt használjuk \url{https://www.kaggle.com/datasets/msambare/fer2013}. Az adatok 48x48 pixeles, szürkeárnyalatos arcképekből állnak. Az arcokat automatikusan úgy regisztrálták, hogy az arc többé-kevésbé középen legyen, és minden képen körülbelül ugyanannyi helyet foglaljon el.

    A feladat az egyes arcok kategorizálása az arckifejezésben megjelenő érzelem alapján a hét kategória egyikébe (0=dühös, 1=undor, 2=félelem, 3=boldog, 4=szomorú, 5=meglepetés, 6=semleges). A gyakorlóhalmaz 28 709 példából, a nyilvános teszthalmaz pedig 3589 példából áll.

    \begin{table}[h]
\begin{tabular}{lll}
Érzelmek    & \begin{tabular}[c]{@{}l@{}}Darabszám\\ (Tanítás)\end{tabular} & \begin{tabular}[c]{@{}l@{}}Darabszám\\ (Tesztelés)\end{tabular} \\
semleges    & 4965                                                          & 1233                                                            \\
meglepődött & 3171                                                          & 831                                                             \\
undor       & 436                                                           & 111                                                             \\
boldogság   & 7215                                                          & 1774                                                            \\
félelem     & 4097                                                          & 1024                                                            \\
szomorúság  & 4830                                                          & 1247                                                            \\
mérges      & 3995                                                          & 958                                                            
\end{tabular}
\end{table}
    

    A nemek osztályozásához a $Kaggle$ – $Gender$ $Classification$ $Dataset$-et használtuk fel \url{https://www.kaggle.com/datasets/cashutosh/gender-classification-dataset}. Az adathalmaz nagyjából $23 200$ női és $23 800$ férfi arc megtisztított és levágott képeit tartalmazza.

    \subsubsection{Tanítás}

    Az arcanalízis rendszerünk tanításához az első lépcsőfokunk a képek pixelértékeit az adathalmaz átlagához és szórásához viszonyítva normalizálni. A második lépés a megfelelő transzformációkat elvégezni a képeken az adathalmaz betöltése során. Az utolsó lépésben, a képeket bemenetként átadjuk egy konvolúciós neurális hálónak klasszifikációra.

    Az arcanalízis 2 különböző hálózatból épül fel. Az egyik hálózat hét alapvető arckifejezés felismeréséért felel, a másik pedig a nemek klasszifikálásáért.
    melyek mind előre tanított ResNet-18 háló továbbtanításán alapszanak.
    A hálózatok utolsó rétege egy-egy teljesen összekapcsolt réteg.
    A hálózatok tanítása során SGD optimalizálót használunk és bináris-, többkategóriás keresztentrópia költségfüggvényekkel mérjük a modellek teljesítményét.
    
	\subsection{Tanítási környezet}

    A különböző hálózatokat Intel(R) Core(TM) i5-7600K CPU @ 3.80GHz processzorral, 16,0 GB DDR4 RAM és NVIDIA GeForce GTX 1660 SUPER 6GB videókártával rendelkező számitógépen tanitottuk, illetve fejlesztettük.

    \subsection{Eredmények}
    \subsubsection{Arc rekonstrukció}
    \subsubsection{Arc analizis}
    A nemek klasszifikálására 97\% pontosságot sikerült elérni, míg az érzelmek klasszifikálására csak 66\%-ot tudtunk elérni.

    \begin{figure}[h]	
		\centering
		\includegraphics[width=1\linewidth]{gender}
        \caption{  A nemek klasszifikálására készült hálózat becslései.}
        \label{fig:gender}
	\end{figure}

    A(z) \ref{fig:gender}. ábrán láthatjuk a modellünk által becsült nemeket.

    \newpage
    \begin{figure}[h]	
		\centering
		\includegraphics[width=1\linewidth]{arcanalizis}
        \caption{  Az arckifejezések klasszifikálására készült hálózat becslései.}
        \label{fig:expr}
	\end{figure}

    A(z) \ref{fig:expr}. ábrán 7 különböző arckifejezésre láthatjuk a becsléseket és megfigyelhetjük, hogy az undort és a félelmet a modellünk képtelen pontosan megbecsülni. Hogy pontosan lássuk a modell milyen kifejezésekre milyen pontossággal ad becslést, készitettünk egy konfuziós mátrixot, amely a(z) \ref{fig:cfmatrix}. ábrán látható.

    \begin{figure}[h]	
		\centering
		\includegraphics[width=1\linewidth]{output_cf_matrix.png}
        \caption{  Az arckifejezések klasszifikálására készült hálózat konfuziós mátrixa.}
        \label{fig:cfmatrix}
	\end{figure}
    
    \subsubsection{Felhasználói felület}
	

	\newpage
	\renewcommand{\refname}{Hivatkozások}
	\begin{thebibliography}{9}
		
		\bibitem{tewari}
		Tewari, A., Zollhofer, M., Kim, H., Garrido, P., Bernard, F., Perez,
		P., Theobalt, C. (2017).
		\textit{Mofa: Model-based deep convolutional face au-
		toencoder for unsupervised monocular reconstruction. In Proceedings of
		the IEEE International Conference on Computer Vision Workshops (pp.
		1274-1283)}
		
		\bibitem{tran}
		Tuan Tran, A., Hassner, T., Masi, I., Medioni, G. (2017). 
		\textit{Regressing
		robust and discriminative 3D morphable models with a very deep neural
		network. In Proceedings of the IEEE conference on computer vision and
		pattern recognition (pp. 5163-5172)}
		
		\bibitem{olszewski}
		Olszewski, K., Lim, J. J., Saito, S., Li, H. (2016).
		\textit{High-fidelity facial and
		speech animation for VR HMDs. ACM Transactions on Graphics (TOG),
		35(6), 1-14}
		
		\bibitem{styner}
		Styner, M. A., Rajamani, K. T., Nolte, L. P., Zsemlye, G., Székely, G.,
		Taylor, C. J., Davies, R. H. (2003, July).
		\textit{ Evaluation of 3D correspondence
		methods for model building. In Biennial International Conference on In-
		formation Processing in Medical Imaging (pp. 63-75). Springer, Berlin,
		Heidelberg}
		
		\bibitem{survey} 
		Morales, A., Piella, G., Sukno, F. M. (2021). 
		\textit{Survey on 3D face re-
		construction from uncalibrated images. Computer Science Review, 40,
		100400.}
		
		\bibitem{auto}
		Kala, R. (2016).
		\textit{On-road intelligent vehicles: Motion planning for intel-
		ligent transportation systems. Butterworth-Heinemann.}	
		
		\bibitem{scanner}
		Kovacs, L., Zimmermann, A., Brockmann, G., Gühring, M., Baurecht,H., Papadopulos, N. A., ... Zeilhofer, H. F. (2006).
		\textit{Three-dimensional
		recording of the human face with a 3D laser scanner. Journal of plastic,
		reconstructive and aesthetic surgery, 59(11), 1193-1202}
		
		\bibitem{blanzvetter}
		Blanz, V., Vetter, T. (1999, July).
		\textit{A morphable model for the synthesis
		of 3D faces. In Proceedings of the 26th annual conference on Computer
		graphics and interactive techniques (pp. 187-194)}
		
		\bibitem{3dmm}
		Egger, B., Smith, W. A., Tewari, A., Wuhrer, S., Zollhoefer, M., Beeler,
		T.,... Vetter, T. (2020).
		\textit{3d morphable face models—past, present, and
		future. ACM Transactions on Graphics (TOG), 39(5), 1-38}
		
		\bibitem{dolphins}
		Cashman, T. J., Fitzgibbon, A. W. (2012).
		\textit{What shape are dolphins?
		building 3d morphable models from 2d images. IEEE transactions on pat-
		tern analysis and machine intelligence, 35(1), 232-244}
		
		\bibitem{photometric}
		Ackermann, J., Goesele, M. (2015).
		\textit{A survey of photometric stereo
			techniques. Foundations and Trends® in Computer Graphics and Vision,
			9(3-4), 149-254, 149–254.}
		
		\bibitem{multiplex}
		Hernández, C., Vogiatzis, G., Brostow, G. J., Stenger, B., Cipolla,
		R. (2007, October).
		\textit{Non-rigid photometric stereo with colored lights. In
			2007 IEEE 11th International Conference on Computer Vision (pp. 1-8).
			IEEE}
		
		\bibitem{hibrid}
		Nehab, D., Rusinkiewicz, S., Davis, J., Ramamoorthi, R. (2005).
		\textit{Efficiently combining positions and normals for precise 3D geometry. ACM transactions on graphics (TOG), 24(3), 536-543.}
			
		\bibitem{patelsmith}
		Patel, A., Smith, W. A. (2012).
		\textit{Driving 3D morphable models using shading cues. Pattern Recognition, 45(5), 1993-2004}
		
		\bibitem{ann}
		Abraham, A. (2005).
		\textit{Artificial neural networks. Handbook of measuring system design}
		
		\bibitem{ann2}
		Jain, A. K., Mao, J., Mohiuddin, K. M. (1996).
		\textit{Artificial neural networks: A tutorial. Computer, 29(3), 31-44}
		
		\bibitem{ann3}
		\textit{MARCELL, Borza. Mesterséges neurális hálózatok matematikai alapjai.}
		
		\bibitem{ann4}
		Tamás, K. (2002).
		\textit{A mesterséges neurális hálók a jövőkutatás
			szolgálatában.}
		
		\bibitem{krenker}
		Krenker, A., Bester, J., Kos, A. (2011).
		\textit{Introduction to the artificial neural networks. Artificial Neural Networks: Methodological Advances and
			Biomedical Applications. InTech, 1-18.}
		
		\bibitem{saragih}
		Saragih, J. M., Lucey, S., Cohn, J. F. (2011, March). 
		\textit{Real-time avatar
			animation from a single image. In 2011 IEEE International Conference
			on Automatic Face and Gesture Recognition (FG) (pp. 117-124). IEEE}
		
		\bibitem{CNN}
		Indolia, S., Goswami, A. K., Mishra, S. P., Asopa, P. (2018).
		\textit{ Conceptual
			understanding of convolutional neural network-a deep learning approach.
			Procedia computer science, 132, 679-688.}
	
	
	\bibitem{synthetic}
	Richardson, E., Sela, M., Kimmel, R. (2016, October). 
	\textit{3D face reconstruction by learning from synthetic data. In 2016 fourth international conference on 3D vision (3DV) (pp. 460-469). IEEE.}
	
	\bibitem{keras}
	Manaswi, N. K. (2018).
	\textit{Understanding and working with Keras. In Deep
		Learning with Applications Using Python (pp. 31-43). Apress, Berkeley,
		CA.}
	
	\bibitem{yudong}
	Guo, Y., Cai, J., Jiang, B., Zheng, J. (2018).
	\textit{Cnn-based real-time
		dense face reconstruction with inverse-rendered photo-realistic face images. IEEE transactions on pattern analysis and machine intelligence,
		41(6), 1294-1307.}
	
	\bibitem{elad}
	 Richardson, E., Sela, M., Kimmel, R. (2016, October).
	\textit{3D face reconstruction by learning from synthetic data. In 2016 fourth international conference on 3D vision (3DV) (pp. 460-469). IEEE.}
	
	\bibitem{yudeng}
	Deng, Y., Yang, J., Xu, S., Chen, D., Jia, Y., Tong, X. (2019).
	\textit{Accurate
		3d face reconstruction with weakly-supervised learning: From single image
		to image set. In Proceedings of the IEEE/CVF Conference on Computer
		Vision and Pattern Recognition Workshops (pp. 0-0)}
	
	\bibitem{chen}
	Chen, D., Hua, G., Wen, F., Sun, J. (2016, October). 
	\textit{Supervised transformer network for efficient face detection. In European Conference on
		Computer Vision (pp. 122-138). Springer, Cham.}
	
	\bibitem{kingma}
	Kingma, D. P., Ba, J. (2014).
	\textit{Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980.}
	
	\bibitem{deca}
	Feng, Y., Feng, H., Black, M. J., Bolkart, T. (2021).
	\textit{Learning an animatable detailed 3D face model from in-the-wild images. ACM Transactions
		on Graphics (TOG), 40(4), 1-13.}
	
	\bibitem{focus}
	Li, C., Morel-Forster, A., Vetter, T., Egger, B., Kortylewski, A. (2021).
	\textit{To fit or not to fit: Model-based Face Reconstruction and Occlusion Segmentation from Weak Supervision. arXiv preprint arXiv:2106.09614.}
	
	\bibitem{flame}
	Tianye Li, Timo Bolkart, Michael. J. Black, Hao Li, and Javier Romero
	(2017).
	\textit{Learning a model of facial shape and expression from 4D scans.
		ACM Transactions on Graphics, (Proc. SIGGRAPH Asia) 36, 6 (2017),
		194:1–194:17.}
	
	\bibitem{liwen}
	Liwen Hu, Shunsuke Saito, Lingyu Wei, Koki Nagano, Jaewoo Seo, Jens
	Fursund, Iman Sadeghi, Carrie Sun, Yen-Chun Chen, and Hao Li. (2017).
	(2017).
	\textit{Avatar Digitization from a Single Image for Real-time Rendering. ACM
		Transactions on Graphics (TOG) 36, 6 (2017), 195:1–195:14.}
	
	\bibitem{bulat}
	Adrian Bulat and Georgios Tzimiropoulos (2017).
	\textit{How far are we from solving the 2D and 3D Face Alignment problem? (and a dataset of 230,000 3D facial landmarks). In International Conference on Computer Vision.}
	
	\bibitem{mohammed}
	Mohammed, S. B., Abdulazeez, A. M. (2021).
	\textit{Deep Convolution Neural
		Network for Facial Expression Recognition. PalArch’s Journal of Archaeology of Egypt/Egyptology, 18(4), 3578-3586.}
	
	\bibitem{arcface}
	Deng, J., Guo, J., Xue, N., and Zafeiriou, S. (2019).
	\textit{Arcface: Additive angular margin loss for deep face recognition. In Proceedings of the
		IEEE/CVF conference on computer vision and pattern recognition (pp.
		4690-4699).}
	
	\bibitem{feafa}
	Yan, Y., Lu, K., Xue, J., Gao, P., and Lyu, J. (2019, July).
	\textit{Feafa: A
		well-annotated dataset for facial expression analysis and 3d facial animation. In 2019 IEEE International Conference on Multimedia and Expo
		Workshops (ICMEW) (pp. 96-101). IEEE.}
	
	\bibitem{paysan}
	Paysan, P., Knothe, R., Amberg, B., Romdhani, S., and Vetter, T. (2009, September).
	\textit{A 3D face model for pose and illumination invariant
		face recognition. In 2009 sixth IEEE international conference on advanced
		video and signal based surveillance (pp. 296-301). Ieee.}

    \bibitem{PCA}
	Castelán, Mario, and Edwin R. Hancock.
	\textit{A simple coupled statistical model for 3d face shape recovery. 18th International Conference on Pattern Recognition (ICPR'06). Vol. 1. IEEE, 2006.}


    \bibitem{resnet}
	Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
	\textit{Deep Residual Learning for Image Recognition. In IEEE Conference on Computer Vision and Pattern Recognition  2016. (CVPR). 770–778.}

    \bibitem{tl}
    Weiss, Karl, Taghi M. Khoshgoftaar, and DingDing Wang.
    \textit{A survey of transfer learning." Journal of Big data 3.1 (2016): 1-40.}

    \bibitem{unet}
    Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
    \textit{U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical image computing and computer-assisted intervention. Springer, 234–241 (2015.)}

    \bibitem{celeba}
    Liu, Z., Luo, P., Wang, X., Tang, X.
    \textit{Deep learning face attributes in the wild. In: Proceedings of the IEEE international conference on computer vision. 2015. p. 3730-3738.}

    \bibitem{ciresan}
    Ciresan, D.C., Gambardella, L.M., Giusti, A., Schmidhuber, J.
    \textit{Deep neural networks segment neuronal membranes in electron microscopy images. In: NIPS, pp. 2852–2860 (2012)}

    \bibitem{diffrenderer}
    Kato, Hiroharu, et al.
    \textit{Differentiable rendering: A survey. arXiv preprint arXiv:2006.12057 (2020).}

	\end{thebibliography}

\end{document}